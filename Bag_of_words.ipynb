{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from toolbox.data_prep_helpers import *\n",
    "from toolbox.evaluation import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from models.bagofwords_classifier import create_model\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Flatten, Activation, Dropout\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.preprocessing.text import text\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 100000\n",
    "n_top_labels = 100\n",
    "normalize_embeddings = False\n",
    "learning_rate = 0.0000001\n",
    "vocab_size = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from cached pickle\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data/pythonquestions/\"\n",
    "total_data = load_data(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = total_data.sample(sample_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100000, 5)\n",
      "(99915, 5)\n",
      "deleting element python from top_tags\n"
     ]
    }
   ],
   "source": [
    "print(data.shape)\n",
    "remove_html_tags(data, [\"Body_q\"])\n",
    "data = data[data[\"tags\"].apply(lambda tags: all([isinstance(t, str) for t in tags]))]\n",
    "print(data.shape)\n",
    "data = reduce_number_of_tags(data, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data) * .8)\n",
    "train_posts = data['Body_q'][:train_size]\n",
    "train_tags = data['tags'][:train_size]\n",
    "test_posts = data['Body_q'][train_size:]\n",
    "test_tags = data['tags'][train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenize = text.Tokenizer(num_words=vocab_size)\n",
    "tokenize.fit_on_texts(train_posts)\n",
    "\n",
    "x_train = tokenize.texts_to_matrix(train_posts)\n",
    "x_test = tokenize.texts_to_matrix(test_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = MultiLabelBinarizer()\n",
    "encoder.fit(train_tags)\n",
    "y_train = encoder.transform(train_tags)\n",
    "y_test = encoder.transform(test_tags)\n",
    "n_col = y_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               25700     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 281,956\n",
      "Trainable params: 281,956\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Returned Model not Compiled yet to better play with optimizers!!\n",
    "model = create_model(input_layer_size=256, vocab_size=vocab_size,output_dim=n_col)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "opt = SGD(lr=learning_rate, momentum=0.9)\n",
    "opt_Adam = Adam(lr = learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam' , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(vocab_size,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.7))\n",
    "model.add(Dense(n_col))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "opt_Adam = Adam(lr = learning_rate)\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam' , metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50401 samples, validate on 5601 samples\n",
      "Epoch 1/20\n",
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Large dropout rate: 0.7 (>0.5). In TensorFlow 2.x, dropout() uses dropout rate instead of keep_prob. Please ensure that this is intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50401/50401 [==============================] - 3s 58us/sample - loss: 0.0781 - accuracy: 0.9814 - val_loss: 0.0425 - val_accuracy: 0.9884\n",
      "Epoch 2/20\n",
      "50401/50401 [==============================] - 3s 52us/sample - loss: 0.0415 - accuracy: 0.9887 - val_loss: 0.0355 - val_accuracy: 0.9892\n",
      "Epoch 3/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0364 - accuracy: 0.9893 - val_loss: 0.0336 - val_accuracy: 0.9895\n",
      "Epoch 4/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0340 - accuracy: 0.9897 - val_loss: 0.0326 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "50401/50401 [==============================] - 3s 50us/sample - loss: 0.0326 - accuracy: 0.9900 - val_loss: 0.0323 - val_accuracy: 0.9898\n",
      "Epoch 6/20\n",
      "50401/50401 [==============================] - 3s 52us/sample - loss: 0.0315 - accuracy: 0.9902 - val_loss: 0.0321 - val_accuracy: 0.9899\n",
      "Epoch 7/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0307 - accuracy: 0.9903 - val_loss: 0.0320 - val_accuracy: 0.9899\n",
      "Epoch 8/20\n",
      "50401/50401 [==============================] - 3s 52us/sample - loss: 0.0299 - accuracy: 0.9904 - val_loss: 0.0319 - val_accuracy: 0.9900\n",
      "Epoch 9/20\n",
      "50401/50401 [==============================] - 3s 55us/sample - loss: 0.0294 - accuracy: 0.9906 - val_loss: 0.0320 - val_accuracy: 0.9900\n",
      "Epoch 10/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
      "Epoch 11/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0283 - accuracy: 0.9908 - val_loss: 0.0322 - val_accuracy: 0.9900\n",
      "Epoch 12/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0277 - accuracy: 0.9909 - val_loss: 0.0323 - val_accuracy: 0.9900\n",
      "Epoch 13/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0273 - accuracy: 0.9910 - val_loss: 0.0328 - val_accuracy: 0.9900\n",
      "Epoch 14/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0269 - accuracy: 0.9911 - val_loss: 0.0328 - val_accuracy: 0.9900\n",
      "Epoch 15/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0265 - accuracy: 0.9911 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 16/20\n",
      "50401/50401 [==============================] - 3s 55us/sample - loss: 0.0262 - accuracy: 0.9912 - val_loss: 0.0329 - val_accuracy: 0.9900\n",
      "Epoch 17/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0257 - accuracy: 0.9913 - val_loss: 0.0333 - val_accuracy: 0.9900\n",
      "Epoch 18/20\n",
      "50401/50401 [==============================] - 3s 54us/sample - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0334 - val_accuracy: 0.9899\n",
      "Epoch 19/20\n",
      "50401/50401 [==============================] - 3s 54us/sample - loss: 0.0251 - accuracy: 0.9914 - val_loss: 0.0334 - val_accuracy: 0.9900\n",
      "Epoch 20/20\n",
      "50401/50401 [==============================] - 3s 55us/sample - loss: 0.0248 - accuracy: 0.9916 - val_loss: 0.0340 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50401 samples, validate on 5601 samples\n",
      "Epoch 1/20\n",
      "50401/50401 [==============================] - 3s 58us/sample - loss: 0.0583 - accuracy: 0.9856 - val_loss: 0.0360 - val_accuracy: 0.9893\n",
      "Epoch 2/20\n",
      "50401/50401 [==============================] - 3s 51us/sample - loss: 0.0320 - accuracy: 0.9901 - val_loss: 0.0331 - val_accuracy: 0.9898\n",
      "Epoch 3/20\n",
      "50401/50401 [==============================] - 2s 47us/sample - loss: 0.0286 - accuracy: 0.9907 - val_loss: 0.0328 - val_accuracy: 0.9897\n",
      "Epoch 4/20\n",
      "50401/50401 [==============================] - 2s 47us/sample - loss: 0.0265 - accuracy: 0.9912 - val_loss: 0.0329 - val_accuracy: 0.9897\n",
      "Epoch 5/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0247 - accuracy: 0.9917 - val_loss: 0.0334 - val_accuracy: 0.9897\n",
      "Epoch 6/20\n",
      "50401/50401 [==============================] - 3s 51us/sample - loss: 0.0231 - accuracy: 0.9922 - val_loss: 0.0344 - val_accuracy: 0.9896\n",
      "Epoch 7/20\n",
      "50401/50401 [==============================] - 3s 53us/sample - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0353 - val_accuracy: 0.9893\n",
      "Epoch 8/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0200 - accuracy: 0.9931 - val_loss: 0.0363 - val_accuracy: 0.9891\n",
      "Epoch 9/20\n",
      "50401/50401 [==============================] - 2s 48us/sample - loss: 0.0186 - accuracy: 0.9936 - val_loss: 0.0377 - val_accuracy: 0.9891\n",
      "Epoch 10/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0172 - accuracy: 0.9941 - val_loss: 0.0386 - val_accuracy: 0.9889\n",
      "Epoch 11/20\n",
      "50401/50401 [==============================] - 2s 48us/sample - loss: 0.0160 - accuracy: 0.9945 - val_loss: 0.0402 - val_accuracy: 0.9887\n",
      "Epoch 12/20\n",
      "50401/50401 [==============================] - 3s 50us/sample - loss: 0.0148 - accuracy: 0.9949 - val_loss: 0.0420 - val_accuracy: 0.9885\n",
      "Epoch 13/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0137 - accuracy: 0.9954 - val_loss: 0.0433 - val_accuracy: 0.9883\n",
      "Epoch 14/20\n",
      "50401/50401 [==============================] - 3s 50us/sample - loss: 0.0126 - accuracy: 0.9958 - val_loss: 0.0452 - val_accuracy: 0.9882\n",
      "Epoch 15/20\n",
      "50401/50401 [==============================] - 3s 52us/sample - loss: 0.0116 - accuracy: 0.9962 - val_loss: 0.0472 - val_accuracy: 0.9878\n",
      "Epoch 16/20\n",
      "50401/50401 [==============================] - 2s 47us/sample - loss: 0.0107 - accuracy: 0.9965 - val_loss: 0.0490 - val_accuracy: 0.9878\n",
      "Epoch 17/20\n",
      "50401/50401 [==============================] - 3s 51us/sample - loss: 0.0098 - accuracy: 0.9969 - val_loss: 0.0512 - val_accuracy: 0.9878\n",
      "Epoch 18/20\n",
      "50401/50401 [==============================] - 3s 52us/sample - loss: 0.0089 - accuracy: 0.9972 - val_loss: 0.0532 - val_accuracy: 0.9876\n",
      "Epoch 19/20\n",
      "50401/50401 [==============================] - 2s 49us/sample - loss: 0.0082 - accuracy: 0.9975 - val_loss: 0.0555 - val_accuracy: 0.9876\n",
      "Epoch 20/20\n",
      "50401/50401 [==============================] - 3s 50us/sample - loss: 0.0074 - accuracy: 0.9978 - val_loss: 0.0578 - val_accuracy: 0.9872\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=64,\n",
    "                    epochs=20,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=opt , metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_train, y_train,\n",
    "                    batch_size=128,\n",
    "                    epochs=30,\n",
    "                    verbose=1,\n",
    "                    validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: ('django',)\n",
      "PREDICTION: ('datetime', 'django')\n",
      "\n",
      "a= {'Locator__creation_date': {'start': datetime.date(2013, 11, 14), 'end': datetime.date(2013, 11, 14)}, 'Locator__employed': u'True', 'Locator__employer_state': u'AL', 'Locator__receiving_hiv_treatment': u'True', 'Locator__hiv_treatment_state': u'AR', 'Locator__mental_health_provider': u'False', 'Locator__parole': u'True', 'Locator__parole_state': u'IA', 'data_model_name': ['Locator']}\n",
      "\n",
      "ast.literal_eval(a)\n",
      "\n",
      "it gives\n",
      "ValueError: malformed string\n",
      "\n",
      "\n",
      "TRUE: ('scipy',)\n",
      "PREDICTION: ('nltk', 'numpy', 'python-2.7', 'scipy', 'ubuntu')\n",
      "\n",
      "I'm starting to work with Python and I've been trying to use some methods of SciPy and SciKits, but when I import the SciPy module I get this error:\n",
      "ImportError: /usr/local/lib/python2.7/dist-packages/scipy/linalg/clapack.so: \n",
      "   undefined symbol: clapack_sgesv \n",
      "\n",
      "I've been looking for a solution but haven't found one yet. This is on Ubuntu 12.10. Can anyone help me?\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ('algorithm', 'class', 'dictionary', 'list', 'string')\n",
      "\n",
      "Here is the program called Telephone:\n",
      " import shelve\n",
      "import string\n",
      "\n",
      "UNKNOWN = 0\n",
      "HOME = 1\n",
      "WORK = 2\n",
      "FAX = 3\n",
      "CELL = 4\n",
      "\n",
      "class phoneentry:\n",
      "    def __init__(self, name = 'Unknown', number = 'Unknown', type = UNKNOWN):\n",
      "            self.name = name\n",
      "            self.number = number\n",
      "            self.type = type\n",
      "\n",
      "    #  create string representation\n",
      "    def __repr__(self):\n",
      "            return('%s:%d' % ( self.name, self.type ))\n",
      "\n",
      "    #  fuzzy compare or two items\n",
      "    def __cmp__(self, that):\n",
      "            this = string.lower(str(self))\n",
      "            that = string.lower(that)\n",
      "            if string.find(this, that) >= 0:\n",
      "                return(0)\n",
      "\n",
      "            return(cmp(this, that))\n",
      "\n",
      "    def showtype(self):\n",
      "            if self.type == UNKNOWN: return('Unknown')\n",
      "            if self.type == HOME: return('Home')\n",
      "            if self.type == WORK: return('Work')\n",
      "            if self.type == FAX: return('Fax')\n",
      "            if self.type == CELL: return('Cellular')\n",
      "\n",
      "class phonedb:\n",
      "\n",
      "    def __init__(self, dbname = 'phonedata'):\n",
      "            self.dbname = dbname;\n",
      "            self.shelve = shelve.open(self.dbname);\n",
      "\n",
      "\n",
      "    def __del__(self):\n",
      "            self.shelve.close()\n",
      "            self.shelve = None\n",
      "\n",
      "    def add(self, name, number, type = HOME):\n",
      "            e = phoneentry(name, number, type)\n",
      "            self.shelve[str(e)] = e\n",
      "\n",
      "\n",
      "    def lookup(self, string):\n",
      "            list = []\n",
      "            for key in self.shelve.keys():\n",
      "                    e = self.shelve[key]\n",
      "                    if cmp(e, string) == 0:\n",
      "                            list.append(e)\n",
      "\n",
      "\n",
      "            return(list)\n",
      "\n",
      "#  if not being loaded as a module, run a small test\n",
      "#if __name__ == '__main__':\n",
      "        #foo = phonedb()\n",
      "        #foo.add('Sean Reifschneider', '970-555-1111', HOME)\n",
      "        #foo.add('Sean Reifschneider', '970-555-2222', CELL)\n",
      "        #foo.add('Evelyn Mitchell', '970-555-1111', HOME)\n",
      "\n",
      "        #print 'First lookup:'\n",
      "        #for entry in foo.lookup('reifsch'):\n",
      "                #print '%-40s %s (%s)' % ( entry.name, entry.number, entry.showtype() )\n",
      "                #print\n",
      "\n",
      "                #print 'Second lookup:'\n",
      "\n",
      "        #for entry in foo.lookup('e'):\n",
      "            #print '%-40s %s (%s)' % ( entry.name, entry.number, entry.showtype() )\n",
      "\n",
      "I had to take this program and modify it to make it better. I've been able to accomplish everything but print a list of the database that contains everyone that has been added with their respective information. Can someone assist me or stir me in the right direction...see below: my code...\n",
      "   from Telephone import *\n",
      "\n",
      "\n",
      "pb = phonedb()\n",
      "\n",
      "while (1):\n",
      "    print \"Welcome to the Telephone Database!\"\n",
      "    print\n",
      "    print \"Please make a selection:\"\n",
      "    print\n",
      "    print \"1) Add new number\"\n",
      "    print\n",
      "    print \"2) Find a number\"\n",
      "    print\n",
      "    print \"3) list all in the directory \"\n",
      "    print\n",
      "    print \"E) exit\"\n",
      "    print\n",
      "    myinput = raw_input(':')\n",
      "    if myinput == \"1\":\n",
      "        print \"you pushed 1\"\n",
      "    if myinput == \"2\":\n",
      "        print \"you pushed 2\"\n",
      "    if myinput == \"3\":\n",
      "        print \"you pushed 3\"\n",
      "\n",
      "    print\n",
      "    if myinput == \"1\":\n",
      "\n",
      "        print \"What is the name of the person you want to add? :\"\n",
      "        p = raw_input(':')\n",
      "        print \"What is the number you want specified for this person? :\"\n",
      "        n = raw_input(':')\n",
      "        print \"What type of communication device is this : (0 = UNKNOWN, 1 = HOME, 2 = WORK, 3 = FAX, 4 = CELL)\"\n",
      "        t = raw_input(':')\n",
      "        if t == '0':\n",
      "            pb.add(p, n, UNKNOWN)\n",
      "        if t == '1':\n",
      "            pb.add(p, n, HOME)\n",
      "        if t == '2':\n",
      "            pb.add(p, n, WORK)\n",
      "        if t == '3':\n",
      "            pb.add(p, n, FAX)\n",
      "        if t == '4':\n",
      "            pb.add(p, n, CELL)\n",
      "\n",
      "    if myinput == \"2\":\n",
      "\n",
      "        print \"Type the name of the person whos number you are looking for :\"\n",
      "        search = raw_input(':')\n",
      "        for entry in pb.lookup(search):\n",
      "            print '%-40s %s (%s)' % (entry.name, entry.number, entry.showtype())\n",
      "\n",
      "    if myinput == \"3\":   # THIS IS WHERE I NEED ASSISTANCE...********\n",
      "        for entry in pb.lookup(\n",
      "            print '%-40s %s (%s)' % (enter.name, entry.number, entry.showtype())\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    if myinput == \"e\" or myinput == \"E\":\n",
      "        break\n",
      "\n",
      "print \"Thanks for playing -- El Gooey\"\n",
      "\n",
      "\n",
      "TRUE: ('python-2.7', 'scipy')\n",
      "PREDICTION: ('numpy', 'scipy')\n",
      "\n",
      "I'm trying to minimise a function of three variables, nonlinear, and very big and nasty. It works in Matlab just fine, but I'm trying to transfer over to python (as a learning experience and more freedom). Anyway, it does work for with the minimize function 'Nelder-Mead', but it is giving me an output that doesn't make sense, so I'm trying to add bounds to my variables. \n",
      "Here's the code:\n",
      "bnds = ((0, 1), (0, 1), (0, 1))\n",
      "x0 = [0.004, 0.1, 0.1]\n",
      "res = minimize(myObjFun, x0, method='L-BFGS-B', bounds=bnds)\n",
      "print(res)\n",
      "\n",
      "The output from Matlab gives me the three values which minimize the function: [0.2182, 0.0684, 0.0048], while the Nelder-Mead in python gave something completely different and way out of the bounds I want (should be between 0 and 1).\n",
      "Here's the error:\n",
      "File \"****/fixedpoints.py\", line 45, in <module>\n",
      "    res = minimize(myObjFun, x0, method='L-BFGS-B', bounds=bnds)\n",
      "File \"/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/optimize/_minimize.py\", line 380, in minimize\n",
      "callback=callback, **options)\n",
      "File \"/opt/local/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/scipy/optimize/lbfgsb.py\", line 304, in _minimize_lbfgsb\n",
      "isave, dsave)\n",
      "TypeError: _lbfgsb.setulb() 6th argument (f) can't be converted to double\n",
      "\n",
      "\n",
      "TRUE: ('django', 'django-models')\n",
      "PREDICTION: ('django', 'django-models', 'django-views')\n",
      "\n",
      "I need translate a choices for a field on the model.\n",
      "I have something like this:\n",
      "from django.utils.translation import ugettext as _\n",
      "from django.db import models\n",
      "\n",
      "class MyModel(models.Model):\n",
      "    TYPES = (\n",
      "        (1, _(\"Option one\")),\n",
      "        (2, _(\"Option two\"))\n",
      "        (3, _(\"Option three\"))\n",
      "    )\n",
      "    type = models.CharField(max_length=50, choices=TYPES)\n",
      "\n",
      "Before this I have a script on the login view:\n",
      "request.session['django_language'] = request.POST.get(\"language\")\n",
      "\n",
      "So, the problem is when django calls the TYPES on MyModel, because the request.session['django_language'] doesn't exist.\n",
      "Any help will be greatly appreciated.\n",
      "Thanks...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_predictions = 300\n",
    "\n",
    "predictions = model.predict(x_test[:n_predictions])\n",
    "\n",
    "l_pred = encoder.inverse_transform(binarize_model_output(predictions, threshold=0.1))\n",
    "l_true = encoder.inverse_transform(y_test[:n_predictions])\n",
    "raw_texts = test_posts[:n_predictions]\n",
    "\n",
    "for pred, act, txt, i in zip(l_pred, l_true, raw_texts, range(5)):\n",
    "    print(f\"TRUE: {act}\\nPREDICTION: {pred}\\n\")\n",
    "    print(txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "\n",
      "normalize_embeddings = False, learning_rate = 1e-07, vocab_size = 1000, epochs=20\n",
      "Parameter Settings:\n",
      " Sample size = 100000, Max. number of words per question = None, Number of Top Labels used = 100\n",
      "\n",
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 512)               512512    \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 100)               51300     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 100)               0         \n",
      "=================================================================\n",
      "Total params: 563,812\n",
      "Trainable params: 563,812\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "threshold is 0.0\n",
      "threshold is 0.01\n",
      "threshold is 0.02\n",
      "threshold is 0.03\n",
      "threshold is 0.04\n",
      "threshold is 0.05\n",
      "threshold is 0.06\n",
      "threshold is 0.07\n",
      "threshold is 0.08\n",
      "threshold is 0.09\n",
      "threshold is 0.1\n",
      "threshold is 0.11\n",
      "threshold is 0.12\n",
      "threshold is 0.13\n",
      "threshold is 0.14\n",
      "threshold is 0.15\n",
      "threshold is 0.16\n",
      "threshold is 0.17\n",
      "threshold is 0.18\n",
      "threshold is 0.19\n",
      "threshold is 0.2\n",
      "threshold is 0.21\n",
      "threshold is 0.22\n",
      "threshold is 0.23\n",
      "threshold is 0.24\n",
      "threshold is 0.25\n",
      "threshold is 0.26\n",
      "threshold is 0.27\n",
      "threshold is 0.28\n",
      "threshold is 0.29\n",
      "threshold is 0.3\n",
      "threshold is 0.31\n",
      "threshold is 0.32\n",
      "threshold is 0.33\n",
      "threshold is 0.34\n",
      "threshold is 0.35000000000000003\n",
      "threshold is 0.36\n",
      "threshold is 0.37\n",
      "threshold is 0.38\n",
      "threshold is 0.39\n",
      "threshold is 0.4\n",
      "threshold is 0.41000000000000003\n",
      "threshold is 0.42\n",
      "threshold is 0.43\n",
      "threshold is 0.44\n",
      "threshold is 0.45\n",
      "threshold is 0.46\n",
      "threshold is 0.47000000000000003\n",
      "threshold is 0.48\n",
      "threshold is 0.49\n",
      "threshold is 0.5\n",
      "threshold is 0.51\n",
      "threshold is 0.52\n",
      "threshold is 0.53\n",
      "threshold is 0.54\n",
      "threshold is 0.55\n",
      "threshold is 0.56\n",
      "threshold is 0.5700000000000001\n",
      "threshold is 0.58\n",
      "threshold is 0.59\n",
      "threshold is 0.6\n",
      "threshold is 0.61\n",
      "threshold is 0.62\n",
      "threshold is 0.63\n",
      "threshold is 0.64\n",
      "threshold is 0.65\n",
      "threshold is 0.66\n",
      "threshold is 0.67\n",
      "threshold is 0.68\n",
      "threshold is 0.6900000000000001\n",
      "threshold is 0.7000000000000001\n",
      "threshold is 0.71\n",
      "threshold is 0.72\n",
      "threshold is 0.73\n",
      "threshold is 0.74\n",
      "threshold is 0.75\n",
      "threshold is 0.76\n",
      "threshold is 0.77\n",
      "threshold is 0.78\n",
      "threshold is 0.79\n",
      "threshold is 0.8\n",
      "threshold is 0.81\n",
      "threshold is 0.8200000000000001\n",
      "threshold is 0.8300000000000001\n",
      "threshold is 0.84\n",
      "threshold is 0.85\n",
      "threshold is 0.86\n",
      "threshold is 0.87\n",
      "threshold is 0.88\n",
      "threshold is 0.89\n",
      "threshold is 0.9\n",
      "threshold is 0.91\n",
      "threshold is 0.92\n",
      "threshold is 0.93\n",
      "threshold is 0.9400000000000001\n",
      "threshold is 0.9500000000000001\n",
      "threshold is 0.96\n",
      "threshold is 0.97\n",
      "threshold is 0.98\n",
      "threshold is 0.99\n",
      "\n",
      "Metrics with optimized threshold of 0.26\n",
      " Macro Evaluation: f1_Score= 0.3951947165607037 , Recall = 0.386513103726339 , Precision = 0.45364693313222726\n",
      " Micro Evaluation: f1_Score= 0.5853658536585366 , Recall = 0.5193621867881549 , Precision = 0.6705882352941176\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[:n_predictions])\n",
    "# l_pred_binary = binarize_model_output(predictions, 0.27)\n",
    "# l_true_binary = y_test[:n_predictions]\n",
    "output_evaluation(model, sample_size, None, n_top_labels, l_true_binary, predictions, normalize_embeddings, learning_rate, vocab_size, n_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
