{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging Stack-Overflow Questions\n",
    "\n",
    "**The data**\n",
    "* Python questions from Stackoverflow: [https://www.kaggle.com/stackoverflow/pythonquestions](https://www.kaggle.com/stackoverflow/pythonquestions)\n",
    "* ~ 600000 questions\n",
    "* each question with 0-5 tags\n",
    "\n",
    "**The problem**\n",
    "\n",
    "Can we predict tags from question / title texts? If so, how well?\n",
    "\n",
    "**Approach**\n",
    "\n",
    "Create several models and compare performances:\n",
    "* Bag-of-words model\n",
    "* sequential LSTM model for question bodies\n",
    "* *composite LSTM model for question bodies + titles*   <== this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dschr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import itertools\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/pythonquestions/\"\n",
    "ft_path = \"alldata.ft\"  # set this to None if you want to train your own fasttext embeddings\n",
    "n_top_labels = 100  # number of top labels to reduce dataset to\n",
    "max_question_words = 100\n",
    "sample_size = 1000  # set to -1 to use entire dataset\n",
    "normalize_embeddings = True  # whether to normalize fasttext embeddings between -1, +1\n",
    "use_titles= False\n",
    "\n",
    "tokenized_field = \"q_title_tokenized\" if use_titles else \"q_all_body_tokenized\"\n",
    "content_field = \"Title\" if use_titles else \"Body_q\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-f5704b9c958c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtoolbox\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata_prep_helpers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"presentation_sample.pkl\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_cache\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\Studium\\TUM\\Kurse\\Informatik\\Semester 5\\ADNLP\\so_nlp\\toolbox\\data_prep_helpers.py\u001b[0m in \u001b[0;36mload_data\u001b[1;34m(data_path, drop_extra_columns, ignore_cache, tokenized_field, content_field, include_answers)\u001b[0m\n\u001b[0;32m    126\u001b[0m     \u001b[0mcache_folder\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"cache\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 128\u001b[1;33m     \u001b[0mc1_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{cache_folder}/{data_path.split('/')[-2]}_0.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    129\u001b[0m     \u001b[0mpkl_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34mf\"{cache_folder}/{data_path.split('/')[-2]}.pkl\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;31m# load cache data pickle if it exists\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "from toolbox.data_prep_helpers import load_data\n",
    "\n",
    "df = load_data(\"presentation_sample.pkl\", ignore_cache=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Slim down number of tags\n",
    "\n",
    "We remove all tags that are not within the top *n_top_label* tags of the dataset. Afterwards, we remove any row that has no tags left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.data_prep_helpers import reduce_number_of_tags\n",
    "\n",
    "df = reduce_number_of_tags(df, n_top_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove HTML Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Body_q\"].iloc[100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.data_prep_helpers import remove_html_tags\n",
    "\n",
    "# question bodies are stored as html code, we need to extract the content only\n",
    "remove_html_tags(df, [\"Body_q\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Body_q\"].iloc[100000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "We need to tokenize questions in order to be able to apply/train embeddings on them.\n",
    "\n",
    "To do this, we use the word_tokenize function from the nltk library ([https://www.nltk.org/api/nltk.tokenize.html](https://www.nltk.org/api/nltk.tokenize.html)) to transform multiple sentences of a question to a 1-dimensional list of tokens. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization example\n",
    "generate_question_level_tokens(\"Please help! How do I format in markdown?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.data_prep_helpers import generate_question_level_tokens\n",
    "\n",
    "df[\"q_body_tokenized\"] = df[\"Body_q\"].apply(generate_question_level_tokens)\n",
    "df[\"q_title_tokenized\"] = df[\"Title\"].apply(generate_question_level_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove samples with too many tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove questions that contain more than max_questions_words words to meet memory limitations. \n",
    "df = df[df[\"q_body_tokenized\"].apply(len).between(1, max_question_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText word embeddings\n",
    "\n",
    "We trained our own embeddings, because Code is often related to certain key words.\"Pandas\" for instance is related to the python library. Hence it's meaning within python code is totally different from it's meaning in pretrained embeddings.\n",
    "\n",
    "\n",
    "Why FastText?\n",
    "\n",
    "FastText includes reasonable mechanisms to deal with words, where no embedding exists. \n",
    "It represents a word as a bag of character n-grams. For words, which are out of vocab it calculates the embedding by combining the specific n-grams. For Training we used skip gram and cbow, where xy turned out to have a better perfomance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word embeddings ONLY with training data\n",
    "# wv = create_Word2Vec_embeddings(train_data, \"Body_q\")\n",
    "# Use FastText to include solution for out-of-vocab words\n",
    "if ft_path is not None:\n",
    "    wv = load_fasttext_embeddings(ft_path)\n",
    "else:\n",
    "    wv = create_FastText_embedding(train_data, content_field)\n",
    "wv.init_sims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_t = df[\"q_title_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))\n",
    "X_b = df[\"q_all_body_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transform data to model-compatible format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pad question embeddings to equal length to unify tensor shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "padding_element = np.array([0.0] * X_train_t.iloc[0].shape[-1])\n",
    "\n",
    "X_t = pad_sequences(X_t, padding=\"post\", dtype='float32', value=padding_element)\n",
    "X_b = pad_sequences(X_b, padding=\"post\", dtype='float32', value=padding_element)\n",
    "print(X_t.shape)\n",
    "print(X_b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target data\n",
    "With the MultiLabelBinarizer we create a (sample x label) matrix where for each record a 1 represents the presence of a certain label and a 0 its absence. (Similar to one-hot-encoding for single class problems) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "label_encoder = MultiLabelBinarizer()\n",
    "label_encoder.fit(df[\"tags\"])\n",
    "y = label_encoder.transform(df[\"tags\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Our title/body model takes title and body token sequences as separate inputs. These inputs are each passed through a masking layer which allows following layers (i.e. the lstm layers) to skip padding elements in the sequence. The masked inputs are processed by two separate lstm layers, whos last output vectors are concatenated to form one big context vector. This context is then passed through a fully connected layer with a sigmoid activation function, which assigns \"independent\" probabilities to each output class.\n",
    "\n",
    "The model is visualized in the diagram below. For this visual example, we go with the following properties:\n",
    "* batch size: 32\n",
    "* sequence length: 50\n",
    "* embedding size: 100\n",
    "* lstm size (each): 64\n",
    "\n",
    "![model architecture](graphics/title_body_model.svg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conduct GridSearch to find \"optimal\" hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from toolbox.training import grid_search_es\n",
    "\n",
    "search_params = {\n",
    "    \"lstm_layer_size\": [256, 128],\n",
    "    \"lstm_dropout\": [0.0, 0.2, 0.4],\n",
    "    \"num_mid_dense\": [0.0,1.0]\n",
    "    \n",
    "    # don't change these:\n",
    "    \"output_dim\": [y.shape[-1]]\n",
    "}\n",
    "\n",
    "all_hists = grid_search_es([X_b, X_t], y, create_model, search_params)\n",
    "\n",
    "best_params, best_hist, best_loss = min(all_hists, key=lambda x: x[2])\n",
    "\n",
    "epoch_lengths = [len(h[\"val_loss\"]) for h in best_hist]\n",
    "print(f\"best combindation: {best_params}\")\n",
    "print(f\"avg min val_loss: {best_loss} -- epoch counts: {epoch_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create train and test dataset split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test split with two datasets. Requires the zip to make the split for the question body and the question title\n",
    "X_train_z, X_test_z, y_train, y_test = train_test_split(list(zip(X_b, X_t)), y, test_size=0.2)\n",
    "X_train = list(zip(*X_train_z))\n",
    "X_test = list(zip(*X_test_z))\n",
    "\n",
    "#Convert to numpy arrays \n",
    "X_train=[np.array(X_train[0]), np.array(X_train[1])]\n",
    "X_test=[np.array(X_test[0]), np.array(X_test[1])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.title_body_lstm import create_model\n",
    "\n",
    "model = create_model(**best_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "import datetime\n",
    "\n",
    "model_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir=\"logs/fit/\" + model_name\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    ModelCheckpoint(filepath=f\"checkpoints/{model_name}\", monitor=\"val_loss\", restore_best_weights=True, verbose=0)\n",
    "]\n",
    "\n",
    "model.fit(x=X_train, y=y_train, batch_size=128, epochs=100, validation_data=[X_test, y_test], callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_model = \"qtb_full_sg.h5\"\n",
    "model = keras.models.load_model(path_to_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1_Micro Score Optimization\n",
    "\n",
    "F1_Score = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "For Multi-Labeling we used the F1_Micro score which calculates the number of \"True Positives\", \"False Positives\" and \"False Negatives\" globally.\n",
    "As we use the sigmoid function within our model we get values between 0 and 1 for every label. Hence it is necessary to define a threshold to decide whether a certain label is predicted (=1). The threshold, that maximizes the f1_micro score is calculated within the output_evaluation function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)\n",
    "opt_thres = output_evaluation(model, sample_size, max_question_words, n_top_labels, y_test, predictions, normalize_embeddings, None, None, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at some examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"validation_questions.pkl\", \"rb\") as in_file:\n",
    "    validation_questions = pickle.load(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 40, 100)\n",
      "(100, 100, 100)\n",
      "(100, 100)\n"
     ]
    }
   ],
   "source": [
    "X_val_t = validation_questions[\"q_title_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))\n",
    "X_val_b = validation_questions[\"q_all_body_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))\n",
    "\n",
    "X_val_t = pad_sequences(X_val_t, padding=\"post\", dtype='float32', value=padding_element, maxlen=X_t.shape[1])\n",
    "X_val_b = pad_sequences(X_val_b, padding=\"post\", dtype='float32', value=padding_element)\n",
    "\n",
    "print(X_val_t.shape)\n",
    "print(X_val_b.shape)\n",
    "\n",
    "y_val = label_encoder.transform(validation_questions[\"tags\"])\n",
    "print(y_val.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRUE: ('machine-learning', 'scikit-learn')\n",
      "PREDICTION: ('scikit-learn',)\n",
      "\n",
      "How to obtain information gain using scikit-learn?\n",
      "\n",
      "I see that DecisionTreeClassifier accepts criterion='entropy', which means that it must be using information gain as a criterion for splitting the decision tree. \n",
      "What I need is the information gain for each feature at the root level, when it is about to split the root node.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('parsing',)\n",
      "PREDICTION: ('nltk',)\n",
      "\n",
      "Python ast and tokenizer\n",
      "\n",
      "In python how would you use the tokenize module in conjunction with the ast module? Both use different node types how would you correlate the two together? Is there a way? Possibly the parser module?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('class',)\n",
      "PREDICTION: ('class',)\n",
      "\n",
      "Python class inheritance\n",
      "\n",
      "I have this code:\n",
      "class A(object):\n",
      "    def __init__(self):\n",
      "       print \" A\"\n",
      "\n",
      "class B(A):\n",
      "    def __init__(self):\n",
      "        print \"B\"\n",
      "x=B()\n",
      "print \"Done\"\n",
      "\n",
      "the result is: \"B\" gets printed \n",
      "why does it not print \"A\", eventhough class B inheritance A\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('json',)\n",
      "PREDICTION: ('json', 'python-requests')\n",
      "\n",
      "python-instagram example (404) Unable to parse response, not valid JSON\n",
      "\n",
      "Here is a example for instagram that does not work. \n",
      "I have found this page but it does not solve my problem, python-instagram is installed and file name is ok. where is the problem?\n",
      "from instagram.client import InstagramAPI\n",
      "api = InstagramAPI(client_id='xxx',\n",
      "               client_secret='xxx')\n",
      "popular_media = api.media_popular(count=20)\n",
      "\n",
      "problem is with api.media_popular .\n",
      "error:\n",
      "raise InstagramClientError('Unable to parse response, not valid JSON.',\n",
      "status_code=response['status'])\n",
      "InstagramClientError: (404) Unable to parse response, not valid JSON.\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('c++', 'multithreading')\n",
      "PREDICTION: ()\n",
      "\n",
      "Do I need multi-threading for this project?\n",
      "\n",
      "Target Platform: Windows XP high school computers\n",
      "Libraries Required: SFML, GLEW, ODE, Python (for embedding)\n",
      "Planned Features that lead me to believe I may need multi-threading:   \n",
      "\n",
      "Up to a hundred robots all interpreting python scripts in real time.\n",
      "All robots and their components in physical simulation with their environment.\n",
      "A detailed environment is generated in large sections around the player.\n",
      "May need to write files to hard drive while the game runs.\n",
      "(In addition to these features, the target platform worries me)\n",
      "\n",
      "Do I need multi-threading for this project?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('arrays', 'numpy')\n",
      "PREDICTION: ('arrays', 'numpy')\n",
      "\n",
      "Get only those elements of array that match all elements of test array?\n",
      "\n",
      "How can I get only the elements of the array that match all the elements of test array?, for instance, if I have:\n",
      ">>> import numpy as np\n",
      "\n",
      ">>> arr = np.array([[0, 0, 1], [1, 0, 1], [1, 0, 1]])\n",
      ">>> arr == [0,0,1]\n",
      "array([[ True,  True,  True],\n",
      "   [False,  True,  True],\n",
      "   [False,  True,  True]], dtype=bool)\n",
      "\n",
      "The solution for arr == [0,0,1] is the index 0\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('windows',)\n",
      "PREDICTION: ('windows',)\n",
      "\n",
      "Run cudamat Makefile.win on Windows 7\n",
      "\n",
      "I used the cmd for Visual Studio 2008 and 2010 to run this make file:\n",
      "cudamat: cudamat.cu cudamat.cuh cudamat_kernels.cu cudamat_kernels.cuh learn.cu learn_kernels.cu learn_kernels.cuh\n",
      "nvcc -O --ptxas-options=-v -o libcudamat.dll --shared cudamat.cu cudamat_kernels.cu -lcublas\n",
      "nvcc -O --ptxas-options=-v -o libcudalearn.dll --shared learn.cu learn_kernels.cu -lcublas\n",
      "\n",
      "clean:\n",
      "rm *.linkinfo *.pyc *.so\n",
      "\n",
      "using command nmake -f Makefile.win from inside the cudamat directory, but i got this:\n",
      "Makefile.win(2) : fatal error U1036: syntax error : too many names to left of '='\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('csv',)\n",
      "PREDICTION: ('csv',)\n",
      "\n",
      "Merging two csv file based on header values in python\n",
      "\n",
      "I have two csv files. the first row of each file is the header and the rest of the rows are the data.\n",
      "first file: \n",
      "a, b, c, d, e, z,\n",
      "1, 2, 3, 4, 5, 6,\n",
      "\n",
      "second file:\n",
      "a, b, c, f, g,\n",
      "7, 8, 9,10,11,\n",
      "\n",
      "and I would like to have a merged csv as follow:\n",
      "a, b, c, d, e, f, g, z,\n",
      "1, 2, 3, 4, 5,  ,  , 6,\n",
      "7, 8, 9,  ,  ,10,11,  ,\n",
      "\n",
      "Any help is appreciated.\n",
      "Thank you\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dictionary', 'list')\n",
      "PREDICTION: ('dictionary', 'list')\n",
      "\n",
      "In python, a good way to remove a list from a list of dicts\n",
      "\n",
      "I have a list of dicts:\n",
      "list =  [{'title': u'Politics', 'id': 1L, 'title_url': u'Politics'}, \n",
      "         {'id': 3L, 'title_url': u'Test', 'title': u'Test'}]\n",
      "\n",
      "I'd like to remove the list item with title = 'Test'\n",
      "What is the best way to do this given that the order of the key/value pairs change?\n",
      "Thanks.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('pip',)\n",
      "PREDICTION: ('django', 'pip')\n",
      "\n",
      "python3.4 pip ImportError: No Module named 'pkg_resources'\n",
      "\n",
      "pip is not working in my python3.4\n",
      "$ pip install django\n",
      "Traceback (most recent call last):\n",
      "   File \"usr/bin/pip\", line 5, in <module>\n",
      "      from pkg_resources import load_entry_point\n",
      "ImportError: No module named 'pkg_resources'\n",
      "$ pip\n",
      "Traceback (most recent call last):\n",
      "   File \"usr/bin/pip\", line 5, in <module>\n",
      "      from pkg_resources import load_entry_point\n",
      "ImportError: No module named 'pkg_resources'\n",
      "\n",
      "How do I fix this? What's the problem? Thanks\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('shell',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Create Python script to ping many hostnames\n",
      "\n",
      "I have a CSV file with the hostnames of 6,000+ servers. I need to ping each one.\n",
      "Any idea how to create a python script like this?\n",
      "Thanks!\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ('string',)\n",
      "\n",
      "Python: Is there a way to split a string of numbers into every 3rd number?\n",
      "\n",
      "For example, if I have a string a=123456789876567543 could i have a list like...\n",
      "123\n",
      "456\n",
      "789\n",
      "876\n",
      "567\n",
      "543\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x', 'tkinter')\n",
      "PREDICTION: ('tkinter',)\n",
      "\n",
      "How to let the Tkinter textarea accept dropping an external file on Python 3.X?\n",
      "\n",
      "I googled some drag and drop tutorial, most of them is about drag and drop the internal element, within the application. But I would like to drop an external file on the textarea, it can displays back the file path to me, it will be nice, but how can I do so? Thanks? Any ideas? \n",
      "PS: Using python3.X\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('php',)\n",
      "PREDICTION: ('xml',)\n",
      "\n",
      "Post HTML data via XMLRPC in Python?\n",
      "\n",
      "I am writing a small script by Python to connect and post content to my WordPress blog. It's pretty straightforward with https://github.com/maxcutler/python-wordpress-xmlrpc\n",
      "However, when i tried to input a HTML data, for example:\n",
      "<b>Hello</b>\n",
      "\n",
      "It appears exactly in the WordPress post (I watch it from the visual editor, and I need to re-format it by copying the data to HTML mode to have the expected result.\n",
      "What should I do with my python script ?\n",
      "Thank you very much\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('arrays', 'numpy')\n",
      "PREDICTION: ('numpy',)\n",
      "\n",
      "Numpy: creating an empty array results in memory error?\n",
      "\n",
      "I need to store a ton of information in a numpy array.  It needs to be of the following shape:\n",
      "facefeature1s = np.empty([2000,64,64,64,32])\n",
      "\n",
      "When I run this, i get a memory error.  What can I do about this?  \n",
      "Error is:\n",
      "    MemoryError                               Traceback (most recent call last)\n",
      "<ipython-input-271-2c56a37b4a7c> in <module>()\n",
      "----> 1 facefeature1s = np.empty([2000,64,64,64,32])\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'mysql')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "Django ORM, group by day\n",
      "\n",
      "I am trying to group products by DAY, however date_created is a datetime field.\n",
      "Product.objects.values('date_created') \\\n",
      "               .annotate(available=Count('available_quantity'))\n",
      "\n",
      "returns:\n",
      "[\n",
      "    {'date_created': datetime.datetime(2012, 4, 14, 13, 3, 6), 'available': 1},\n",
      "    {'date_created': datetime.datetime(2012, 4, 14, 17, 12, 9), 'available': 1},\n",
      "    ...\n",
      "]\n",
      "\n",
      "I want:\n",
      "[\n",
      "    {'date_created': datetime.datetime(2012, 4, 14), 'available': 2}, ...\n",
      "]\n",
      "\n",
      "edit: database backend MYSQL\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('image',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Python 3.1 image library\n",
      "\n",
      "So, is there an image processing library for Python 3.x? There is Python Imaging Library (PIL) but the last supported Python version is 2.7 (\"A version for 3.X will be released later.\")  \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('file',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Replacing commas with blank spaces from a read in text file\n",
      "\n",
      "import os\n",
      "\n",
      "os.chdir('my directory')\n",
      "data = open('text.txt', 'r')\n",
      "data = data.replace(\",\", \" \")\n",
      "print(data)\n",
      "\n",
      "I get the error: \n",
      "\n",
      "AttributeError: '_io.TextIOWrapper' object has no attribute 'replace'\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('string',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Python: how to print range a-z?\n",
      "\n",
      "1. Print a-n: a b c d e f g h i j k l m n\n",
      "2. Every second in a-n: a c e g i k m\n",
      "3. Append a-n to index of urls{hello.com/, hej.com/, ..., hallo.com/}: hello.com/a hej.com/b ... hallo.com/n\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('numpy',)\n",
      "PREDICTION: ('arrays', 'numpy')\n",
      "\n",
      "How to efficiently shuffle numpy array in chunks\n",
      "\n",
      "I have a numpy array that looks like the following [-1,0,1,0,1,2,1,2,3,...,n-1,n,n+1,n,n+1,n+2..]\n",
      "I would like to shuffle the array in chunks of 3, is there an efficient way to do it in numpy?\n",
      "I know you can shuffle a numpy array using the following shuffle method, but this gives me a fully shuffled array. Is there a way to shuffle it in chunks in numpy? \n",
      "import numpy.random as rng\n",
      "\n",
      "ind = numpy.arange(100)\n",
      "rng = numpy.random.RandomState(123)\n",
      "rng.shuffle(ind)\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('module',)\n",
      "PREDICTION: ('python-2.7', 'python-3.x')\n",
      "\n",
      "Can I install a module once, then send the .py somewhere else and have it still work?\n",
      "\n",
      "Just wondering, if I installed a module for python, (for example, pygame) and sent the .py to my school account, would I still need to send the module in the folder with it or would it just store the module within the .py? \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('mysql',)\n",
      "PREDICTION: ('mysql',)\n",
      "\n",
      "How to install Mysql package for python on Visual Studio 2013\n",
      "\n",
      "I am new to python. I am using Visual Studio + python tool to develop python. I am trying to learn how to install the mysql package/library as I need to develop code to interact with the mydql db server.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('import',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Error on import MySQLdb\n",
      "\n",
      "i am using python 2.7.2 (windows 7) and i cant import MySQLdb, error:\n",
      "Traceback (most recent call last):\n",
      "File \"<pyshell#1>\", line 1, in <module>\n",
      "import MySQLdb\n",
      "File \"C:\\Python27\\lib\\MySQLdb\\__init__.py\", line 19, in <module>\n",
      "import _mysql\n",
      "ImportError: No module named _mysql\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('file', 'python-2.7')\n",
      "PREDICTION: ('file',)\n",
      "\n",
      "Python File I/O:How to know if text exist on a line and go to the next line\n",
      "\n",
      "In python file io I get just frustrated because, when I try to write to the next line it just doesnt seem to work.\n",
      "Ive tried \"\\n\" but It just erases the existing text in the file\n",
      "fo = open(\"acckeys.txt\",\"w+\")\n",
      "fo.write(psw+\"_\"+usr+\"\\n\")\n",
      "\n",
      "So how would I check if text already exists in a line and write to the next line without erasing the existing text?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('regex',)\n",
      "PREDICTION: ('regex',)\n",
      "\n",
      "Python partition string with regular expressions\n",
      "\n",
      "I am trying to clean text strings using Python's partition and regular expressions. For example:\n",
      "testString = 'Tre BrÃ¶ders VÃ¤g 6 2tr'\n",
      "sep = '[0-9]tr'\n",
      "head,sep,tail = testString.partition(sep)\n",
      "head\n",
      ">>>'Tre Br\\xc3\\xb6ders V\\xc3\\xa4g 6 2tr'\n",
      "\n",
      "The head still contains the 2tr that I want to remove. I'm not that good with regex, but shouldn't [0-9] do the trick?\n",
      "The output I would expect from this example would be\n",
      "head\n",
      ">>> 'Tre Br\\xc3\\xb6ders V\\xc3\\xa4g 6\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('apache', 'django')\n",
      "\n",
      "uwsgi + django via Nginx - uwsgi settings/spawn?\n",
      "\n",
      "I am leaning towards uwsgi+nginx for my Django app, can anyone share the best method for starting up my uwsgi processes? Does anyone have experience tuning uwsgi? \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('linux',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Where to start to write a Python script for sync local directory to Google Drive?\n",
      "\n",
      "I am learning Python and because of lack of google drive client for Linux. I want to write a simple script to just sync the local directory with google drive. It doesn't have to be fancy and rich feature. Just a command line and do the sync manually is OK. \n",
      "Is it there's any existing projects I can start with? Or anyone can list me some topics I should start learning for it?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('csv',)\n",
      "PREDICTION: ('csv',)\n",
      "\n",
      "Format csv cells as text with python\n",
      "\n",
      "I am giving a row of data to write to a csv file. They are mostly float type numbers. But when it writes to the csv file, the cells are default in custom format. So if I have an input number like 3.25, it prints as \"Mar 25\". How can I avoid this?\n",
      "This is the piece of code:   \n",
      "data = [0.21, 3.25, 25.9, 5.2]  \n",
      "f = open('Boot.csv','w')  \n",
      "out = csv.writer(f, delimiter=';', quoting=csv.QUOTE_NONE)  \n",
      "out.writerow(data)  \n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('windows',)\n",
      "PREDICTION: ('windows',)\n",
      "\n",
      "\"Open with...\" a file on Windows, with a python application\n",
      "\n",
      "I am trying to figure out how to make a python program open a file when a user right clicks on the file and selects \"Open With\". For example, I want a user to be able right click on a text file and to select my program so that my program can process the text file. Is the name of the text file passed into my program someway? Thanks.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('numpy', 'scipy')\n",
      "PREDICTION: ('numpy', 'scipy')\n",
      "\n",
      "Sigmoidal curve fit, how to get the value of x when y=0.5\n",
      "\n",
      "I want to solve the following function so that after fitting, I want to get the value of x when y=0.5.\n",
      "The function:\n",
      "import numpy as np\n",
      "from scipy.optimize import curve_fit\n",
      "\n",
      "def sigmoid(x, b, c):\n",
      "    y = 1 / (1 + c*np.exp(-b*x))\n",
      "    return y\n",
      "\n",
      "x_data = [4, 6, 8, 10]\n",
      "y_data = [0.86, 0.73, 0.53, 0.3]\n",
      "\n",
      "popt, pcov = curve_fit(sigmoid, x_data, y_data,(28.14,-0.25))\n",
      "\n",
      "please explain how would you carry out this using python!\n",
      "Thanks! \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('selenium',)\n",
      "PREDICTION: ('selenium',)\n",
      "\n",
      "Define custom function in selenium python\n",
      "\n",
      "How I can define custom function and then use it in test function, it works when I run single test case but don't work when I run multiple test cases.\n",
      "class AlphaTest(unittest.TestCase):\n",
      "        def setUp(self):\n",
      "            self.driver = webdriver.Firefox()\n",
      "            self.driver.implicitly_wait(30)\n",
      "            self.driver.get(\"http://google.com/\")\n",
      "\n",
      "         def asserTrueId(self, value):\n",
      "             self.assertTrue(self.driver.find_element_by_id(value))\n",
      "             time.sleep(1)\n",
      "\n",
      "\n",
      "         def test_flush_cache(self):\n",
      "            self.asserTrueId(\"block-menu-menu-menu-for-directories\")\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x',)\n",
      "PREDICTION: ('list', 'python-3.x')\n",
      "\n",
      "Error for x in range: TypeError: 'type' object is not iterable\n",
      "\n",
      "I'm trying to run a program in which the user types two words and I have to find the last letter of that word. After that, I have to find out if that letter is in the second word. I started of like this: \n",
      "x=input('Type a word')\n",
      "y=input('Type another word')\n",
      "for x in range:\n",
      "    print (x[-1])\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('api', 'django')\n",
      "\n",
      "Creating api tokens for third parties\n",
      "\n",
      "I'm working on an application where third parties are interested in integrating with us. I would like to create a token for each user and was wondering what is the most efficient and common way in django? I tried to find one, and found this which looks promising:\n",
      "https://github.com/jpulgarin/django-tokenapi\n",
      "Obviously out of the box it wont work, but I can implement it similarly. The above project basically uses the sha hashing algorithm. Is it safe to use this or  MD5 for api tokens? Any help is appreciated!\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'python-2.7')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "Django Project: django-admin.py: command not found\n",
      "\n",
      "I'm trying to create a Django project. I've looked up solutions everywhere and it is still not working.\n",
      "I am running Python 2.7 and Django 1.3.1.\n",
      "I have tried to create a symbolic link but it doesn't work because django-admin.py already exists.\n",
      "Here is the bash:\n",
      "user@user:~$ django-admin.py startproject mysite\n",
      "django-admin.py: command not found\n",
      "\n",
      "user@user:~$ sudo ln -s /usr/lib/python2.7/dist-packages/django/bin/django-adminpy /usr/local/bin/django-admin.py\n",
      "ln: failed to create symbolic link `/usr/local/bin/django-admin.py': File exists\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('html', 'wxpython')\n",
      "PREDICTION: ('wxpython',)\n",
      "\n",
      "wxPython GUI on a web page?\n",
      "\n",
      "Is it possible to embed a wxPython based GUI in an HTML page?\n",
      "If not, is there any other option other than Java applets to make GUIs that can be embedded onto an HTML page?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('ipython',)\n",
      "PREDICTION: ('ipython',)\n",
      "\n",
      "Reload module on remote ipengine when using ipython\n",
      "\n",
      "Hoping this has a straightforward answer that I missed from my reading of the docs. Following is the problem -\n",
      "\n",
      "I have a module loaded on all ipengine(s) on startup\n",
      "I've since made changes to the module\n",
      "I want these changes propagated to the remote ipengine(s) i.e. I want the module to be reloaded in all the remote instances\n",
      "\n",
      "How can this be accomplished?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "duplicate table (identical) including primary key - using django south\n",
      "\n",
      "I'm using south data migration to move data from one table to another (between django apps)\n",
      "Its moving all the data as it suppose to but, problem is its not duplication the primary key (ID), instead creating a new one (in the new table) which make sense..\n",
      "But how can I make a new table identical, including the id field (which is default, not defined in models)\n",
      "using mysql\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ('file', 'list')\n",
      "\n",
      "Read python list from a file\n",
      "\n",
      "I printed a list l to a file using \n",
      "f = open('a.txt', 'a')\n",
      "f.write(str(l))\n",
      "\n",
      "Now, How can I  retrieve the list from the file.\n",
      "And the list l is a list of list of dictionaries.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x',)\n",
      "PREDICTION: ('unicode',)\n",
      "\n",
      "String to utf-8 byte conversion\n",
      "\n",
      "I am developing a websocket server and I need to send to the client '\\x81' encoded in utf-8 and when i do:\n",
      "chr(129).encode('utf-8') it returns b'\\xc2\\x81'.\n",
      "I expect b\\x81.\n",
      "Thank you very much!\n",
      "ps: i am complete newbie\n",
      "Finally I have found it. I have used it bytes([129, 21, 34])\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('tuples',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "Union of 2 tuples python\n",
      "\n",
      "I have two tuples:\n",
      " a= ('girl', 'boy') \n",
      " b= ('boy', 'sex')\n",
      "\n",
      "How can I get the following in Python?\n",
      "    c = ('girl','boy','sex')\n",
      "\n",
      "In words, I want to get union of the two tuples.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('pandas',)\n",
      "PREDICTION: ('datetime', 'pandas')\n",
      "\n",
      "pandas.merge: match the nearest time stamp >= the series of timestamps\n",
      "\n",
      "I have two dataframes, both of which contain an irregularly spaced, millisecond resolution timestamp column. My goal here is to match up the rows so that for each matched row, 1) the first time stamp is always smaller or equal to the second timestamp, and 2) the matched timestamps are the closest for all pairs of timestamps satisfying 1). \n",
      "Is there any way to do this with pandas.merge?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('shell',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Monitoring vi usage\n",
      "\n",
      "I have a file in which I have stored information about users: username, full name, group, etc.  \n",
      "I have to write a \"monitoring\" shell script, that saves in a file called log.txt all the users (username, full name, group) that execute a vi command more than once per minute. The log file should also contain the time when the vi command was started. \n",
      "I know that I should use the ps command, but since I'm new to shell scripting, I need Your help.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dataframe', 'dictionary', 'pandas')\n",
      "PREDICTION: ('pandas',)\n",
      "\n",
      "Lookup values with different column names in pandas\n",
      "\n",
      "I have 2 pandas dataframes df1 and df2\n",
      "Name   No\n",
      "A      1\n",
      "A      2\n",
      "B      5\n",
      "\n",
      "Player Gender\n",
      "A      F\n",
      "B      M\n",
      "C      F\n",
      "\n",
      "I would like to create a new column sex in the df1 dataframe, using corresponding values from the column gender in df2. The columns used to look up are Name in df1 and Player in df2.\n",
      "Really appreciate any help\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('pygame',)\n",
      "PREDICTION: ('pygame',)\n",
      "\n",
      "Setting the colorkey doesn't make that color transparent (Python/Pygame)\n",
      "\n",
      "As said in the title, I am having trouble making one color transparent on a sprite that I have. I set the colorkey to white, but the white spaces on the sprite do not become transparent.\n",
      "Here's what I have:\n",
      "player_image = pygame.image.load(\"blanksprite.png\").convert()\n",
      "player_image.set_colorkey(white)\n",
      "screen.blit(player_image, [x,y])\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "Python - Count occurrences of certain ranges in a list\n",
      "\n",
      "So basically I want to count the number of occurrences a floating point appears in a given list.  For example: a list of grades (all scores out of 100) are inputted by the user and they are sorted in groups of ten.  How many times do scores from 0-10, 10-20, 20-30.. etc) appear?  Like test score distribution.  I know I can use the count function but since I'm not looking for specific numbers I'm having trouble.  Is there a away to combine the count and range?  Thanks for any help.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('matplotlib', 'plot')\n",
      "PREDICTION: ('matplotlib',)\n",
      "\n",
      "Python Matplotlib lines in scatter plot\n",
      "\n",
      "Is there a way to influence which points are connected in a scatter plot?\n",
      "I want a scatter plot where the points which are close together are connected. When I plot with the plot(x,y) command, the line between the points depends on the order of the lists which is not what I want.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dictionary',)\n",
      "PREDICTION: ('dictionary',)\n",
      "\n",
      "Python if key in kwargs and key is true\n",
      "\n",
      "if 'force' in kwargs and kwargs['force'] is True:\n",
      "\n",
      "It feels like there should be a better way of writing this condition since I'm repeating both the key and variable.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('javascript', 'regex')\n",
      "PREDICTION: ('regex',)\n",
      "\n",
      "How to match text or numbers inside parenthesis?\n",
      "\n",
      "I am looking for a formula that matches with numbers and parenthesis.\n",
      "\"Please answer your name of bank.(1) (bank of america)\"\n",
      "\n",
      "For (1) I used \\d([1])\n",
      "For (bank of america) I came up with \\*([a-b])\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Ignore unpickleable objects when pickling\n",
      "\n",
      "I have a rather unique case where my Python program generates a large amount of dynamic code (such as dynamically generated classes and lambdas), and it needs to save its state with Pickle. I'd like to preserve as much as possible, but it's acceptable to simply fail to preserve objects that are unpickleable. \n",
      "In other words, I'd like to be able to pickle the dict mydict, which contains some unpickleable objects, by simply executing del mydict[unpickleablekey] for every unpickleable object.\n",
      "What's the simplest and most Pythonic way to implement this?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('pandas', 'pip')\n",
      "PREDICTION: ('pip',)\n",
      "\n",
      "Quandl cannot install properly using pip and similar installation\n",
      "\n",
      "I tried every possible conventional installation of Quandl module in Python (i.e. via pip, sudo, etc.) but I get persistent errors. First I encountered a permission error that I solved using the command:\n",
      "\n",
      "sudo python setup.py install --user\n",
      "\n",
      "Now I encounter a new problem as follows:\n",
      "\n",
      "/usr/bin/pip:5: UserWarning: Module dap was already imported from None, but /usr/lib/python2.7/dist-packages is being added to sys.path\n",
      "    from pkg_resources import load_entry_point\n",
      "  Requirement already satisfied (use --upgrade to upgrade): Quandl in /home/planet_hunter/.local/lib/python2.7/site-packages/Quandl-2.8.9-py2.7.egg\n",
      "   Cleaning up...\n",
      "\n",
      "Any suggestions? Greatly appreaciate it.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('tkinter',)\n",
      "PREDICTION: ('tkinter',)\n",
      "\n",
      "how to justify text in label in tkinter in python Need justify in tkinter\n",
      "\n",
      "In Tkinter in Python:\n",
      "I have a table with a different label. How can I justify the text that is in the label? Because It is a table and the texts in different labels come together!\n",
      "from tkinter import *\n",
      "root=Tk()\n",
      "a=Label(root,text='Hello World!')\n",
      "a.pack()\n",
      "a.place(x=200,y=200)\n",
      "b=Label(root,text='Bye World')\n",
      "b.pack()\n",
      "b.place(x=200,y=100)\n",
      "\n",
      "I want something for justifying in center some text in label but it is not something that I need plz check this: link\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "How can I determine the dimensionality of a list?\n",
      "\n",
      "How do I determine the dimensionality of a list programmatically? Thanks.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('google-app-engine',)\n",
      "PREDICTION: ('google-app-engine',)\n",
      "\n",
      "Is there something like `ForeignKey` in Google App Engine's `webapp`?\n",
      "\n",
      "I'm using Google App Engine with their webapp framework. Is there something like Django's ForeigKey in webapp? i.e. I have a model and I want it to have a property/field that points at another model. Possible?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('logging',)\n",
      "PREDICTION: ('logging',)\n",
      "\n",
      "python logging.basicConfig\n",
      "\n",
      "I have seen this in a lot of python code what does this do? What is it useful for?\n",
      "logging.basicConfig(level=loglevel,format=myname)\n",
      "Please and thank you.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'postgresql')\n",
      "PREDICTION: ('datetime', 'django')\n",
      "\n",
      "python django: convert the postgresql timestamp to datetime\n",
      "\n",
      "I have a postgresql table with a timestamp field, among other fields. \n",
      "How can I convert this timestamp field to a standard datetime python object and get the date like this: \"Apr 23\"\n",
      "I know how to do it in the django template (with the 'date' template tag), I need to do in views.py so I can create an array with these dates and pass it to the django template. \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list',)\n",
      "PREDICTION: ()\n",
      "\n",
      "How to check if permutations have equal parity?\n",
      "\n",
      "I am looking for a way to check if 2 permutations (represented by lists) are of the same parity. Note that I am not interested if they are even or odd parity, just the equality.\n",
      "I am new to Python and my naive solution is given below as a reply. I am looking forward to Python gurus showing me some cool tricks to achieve the same in lesser, more elegant Python code.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('algorithm',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "splitting list in chunks of balanced weight\n",
      "\n",
      "I need an algorithm to split a list of values into such chunks, that sum of values in every chunk is (approximately) equals (its some variation of Knapsack problem, I suppose)\n",
      "So, for example [1, 2, 1, 4, 10, 3, 8] => [[8, 2], [10], [1, 3, 1, 4]]\n",
      "Chunks of equal lengths are preferred, but it's not a constraint. \n",
      "Python is preferred language, but others are welcome as well\n",
      "Edit: number of chunks is defined\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('web-scraping',)\n",
      "PREDICTION: ('javascript', 'scrapy', 'web-scraping')\n",
      "\n",
      "Scraping ajax pages which return javascript files that generate html nodes\n",
      "\n",
      "Some pages do not return raw data (like json or xml or html) on ajax. Instead they use some framework like dojo where ajax calls return js files which somehow populate the html nodes.\n",
      "I am wondering if there is a non Selenium strategy to scrapy data from these pages. \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dictionary', 'python-3.x')\n",
      "PREDICTION: ('dictionary',)\n",
      "\n",
      "Verifying If key or value exists in dictionary, works for char and fails for number\n",
      "\n",
      "Why is below program returns nothing when I provide input 1 or 3. And works in case of c. \n",
      "#!/usr/local/bin/python3\n",
      "\n",
      "d = {'a':1, 'b':3, 8:'c'}\n",
      "\n",
      "x = input()\n",
      "if x in d.values():\n",
      "        print('In a dictionary')\n",
      "\n",
      "UPDATE:\n",
      "Same for key also if I provide a or b. It works. For 8, it returns none. \n",
      "y = input()\n",
      "\n",
      "if y in d:\n",
      "        print('key in dictionary')\n",
      "\n",
      "What should I do for these?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('flask',)\n",
      "PREDICTION: ('flask',)\n",
      "\n",
      "Flask - Correct signal to subscribe to log after a request was finished?\n",
      "\n",
      "I want to log requests (ie. user page views) to a database, but I want only to log the request metadata to a DB after the request was finished and data was successfully sent to the client.\n",
      "Does flask request_tearing_down is the correct signal to subscribe? How about request_finished?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'django-models', 'django-rest-framework')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "How do I modify a model field and then send it using the Rest Framework in Python/Django?\n",
      "\n",
      "Hello I need to modify some data before the rest framework sends it to a client. The data being sent is from a model object.\n",
      "Here's a code example of my model.\n",
      "class UserOptions(models.Model):\n",
      "    options = models.TextField(null=False, null=True)\n",
      "\n",
      "Now when the client requests a specific users options I need to modify options by adding a combination of elements from 2-3 other models into a big JSON String. How can I accomplish this, I assume through a Serializer but I'm not sure how to specifically modify a requested field accordingly.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "Django filter filter with lists\n",
      "\n",
      "So, I have this model:\n",
      "class Product(models.Model):\n",
      "    colors = models.TextField(max_length=150,default = 'blue,green,blue')\n",
      "\n",
      "and i want to filter it with a list of colors for example.\n",
      "Any idea on how can i do it?\n",
      "colors = [\"blue\",\"green\"]\n",
      "I need something like this.\n",
      "products = Product.objects.filter(colors__icontains = colors)\n",
      "\n",
      "Any kind of help or sugestion on how can i modify the model to filter will be apreciated .\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('linux', 'shell', 'subprocess')\n",
      "PREDICTION: ('subprocess',)\n",
      "\n",
      "Python: subprocess call doesn't recognize * wildcard character?\n",
      "\n",
      "I want to remove all the *.ts in file. os.remove didn't work.\n",
      "And this doesn't expand *\n",
      ">>> args = ['rm', '*.ts']\n",
      ">>> p = subprocess.call(args)\n",
      "rm: *.ts No such file or directory\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('database', 'django')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "how to switch into a single database among multiple databases at run time in django?\n",
      "\n",
      "how to switch into a single database among multiple databases at run time in django?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('matplotlib',)\n",
      "PREDICTION: ('matplotlib',)\n",
      "\n",
      "How can I make a scatter plot colored by density in matplotlib?\n",
      "\n",
      "I'd like to make a scatter plot where each point is colored by the spatial density of nearby points.  \n",
      "I've come across a very similar question, which shows an example of this using R:\n",
      "R Scatter Plot: symbol color represents number of overlapping points\n",
      "What's the best way to accomplish something similar in python using matplotlib?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('c', 'java')\n",
      "PREDICTION: ()\n",
      "\n",
      "How does python represent such large integers?\n",
      "\n",
      "In C, C++, and Java, an integer has a certain range. One thing I realized in Python is that I can calculate really large integers such as pow(2, 100). The same equivalent code, in C, pow(2, 100) would clearly cause an overflow since in 32-bit architecture, the unsigned integer type ranges from 0 to 2^32-1. How is it possible for Python to calculate these large numbers?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('javascript',)\n",
      "PREDICTION: ()\n",
      "\n",
      "Browser not connecting to server with websocket\n",
      "\n",
      "I am hosting my app with Heroku and using websockets. When the browser sends a request the connection fails due to this error message:\n",
      "Firefox can't establish a connection to the server at wss://shrouded-dawn-5557.herokuapp.com/ws \n",
      "In my javascript file I create a new websocket object as:\n",
      "ws = new WebSocket(\"ws://\"+ location.host +\"/ws\");\n",
      "\n",
      "Why is this not making the connection to the server.\n",
      "Thanks\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x', 'python-requests')\n",
      "PREDICTION: ('python-requests',)\n",
      "\n",
      "Python Requests Login not working\n",
      "\n",
      "I am trying to login to this website:\n",
      "https://www.fotocommunity.de/login\n",
      "My Python script looks like this:\n",
      "import requests\n",
      "\n",
      "payload = {\n",
      "    'login[login]': 'myUser',\n",
      "    'login[pass]': 'myPassword',\n",
      "    'login[vorname]':''\n",
      "}\n",
      "\n",
      "with requests.Session() as c:\n",
      "\n",
      "    c.post('https://www.fotocommunity.de/login', data=payload)\n",
      "    r=c.get('http://www.fotocommunity.de/pc/pc/channel/8/extra/new/display/32815218')\n",
      "\n",
      "print(r.content)\n",
      "\n",
      "It is somehow not working. I dont know what I m doing wrong.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-3.x',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "Python: Accessing list as it is comprehended\n",
      "\n",
      "Is there a way to access the list as it is comprehended? In particular I'd like to iterate once again over elements already added.\n",
      "for example, im looking for something like this:\n",
      "[x for x in range(foo) if x not in self]\n",
      "\n",
      "or\n",
      "[x for x in range(foo) if any(y for y in self)]\n",
      "\n",
      "where self would be the just-comprehended list itself.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('tkinter',)\n",
      "PREDICTION: ('tkinter',)\n",
      "\n",
      "ttk.Entry.select_range() works with Button, but not ttk.Button in python / tkinter?\n",
      "\n",
      "Can some one please explain why entry.select_range() works with a Button, but not a ttk.Button?\n",
      "from tkinter import *\n",
      "from tkinter import ttk\n",
      "\n",
      "root = Tk()\n",
      "\n",
      "entry = ttk.Entry(root)\n",
      "entry.pack()\n",
      "\n",
      "#This works\n",
      "button = Button(root, text=\"Select your text\", command=lambda:\n",
      "                    entry.select_range(0, END))\n",
      "\n",
      "#but this doesn't\n",
      "##button = ttk.Button(root, text=\"Select your text\", command=lambda:\n",
      "##                    entry.select_range(0, END))\n",
      "\n",
      "button.pack()\n",
      "\n",
      "root.mainloop()\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('matplotlib',)\n",
      "PREDICTION: ('matplotlib',)\n",
      "\n",
      "How to set the size of a figure in Python matplotlib\n",
      "\n",
      "Could someone tell me, why the size of the figure generated by the code below is not as expected. \n",
      "How can I modify this code to generate a picture with 100*400 pixels?\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "fig  = plt.figure(figsize=(1,4),dpi=100,facecolor = 'red')\n",
      "plt.show(fig)\n",
      "\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-2.7',)\n",
      "PREDICTION: ('list',)\n",
      "\n",
      "How to get common elements of two lists, which are themselves lists in python\n",
      "\n",
      "I have two lists of lists:\n",
      "l1 = [[3,1],[1,2],[1,'a'],[1,4]]\n",
      "l2 = [[3,1],[1,4],[1,5],[1,'a']]\n",
      "\n",
      "and I want to get their intersection, i.e., [[3,1],[1,4],[1,'a']]. How can I do this?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('string',)\n",
      "PREDICTION: ('string',)\n",
      "\n",
      "How do I find the longest string in Python?\n",
      "\n",
      "Something like max(len(s1), len(s2)) will only return the maximum length. But if I actually want to find out which string is longer, and perhaps save it to another string, how is that done? max(s1,s2) seems to return the string with the larger value, but not necessarily the longest. \n",
      "Note: this has to be done without lists or arrays.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('numpy',)\n",
      "PREDICTION: ('numpy',)\n",
      "\n",
      "shape of Vector in numpy\n",
      "\n",
      "I am confused by the fact that\n",
      "a = np.array([1,2])\n",
      "a.T == a  # True\n",
      "\n",
      "and also\n",
      "I = np.array([[1,0],[0,1]])\n",
      "np.dot(a, I) = np.dot(I, a) # both sides work\n",
      "\n",
      "Is the shape of vector (or array) in this case 1*2 or 2*1 ?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'flask')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "Python - How are signals different from pubsub?\n",
      "\n",
      "Django and Flask make use of signals â the latter uses the Blinker library. In the context of Python, Blinker and the Python pubsub library, how do signals and pubsub compare? When would I use one or the other?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('machine-learning',)\n",
      "PREDICTION: ('machine-learning', 'scikit-learn')\n",
      "\n",
      "Using splitWithProportion on ClassificationDataSet\n",
      "\n",
      "I am following pybrain's tutorial on Classification with Feed-Forward Neural Networks, and I'm trying to split my data into testing & training data sets using the following method:\n",
      "training, testing = alldata.splitWithProportion( 0.25 )\n",
      "\n",
      "By the way they describe this in the tutorial, training & testing should both be of type ClassificationDataSet, since alldata is of that type. However, in my code the type of these objects is pybrain.datasets.supervised.SupervisedDataSet. \n",
      "How can I split my ClassificationDataSet into two ClassificationDataSet objects with a proportion?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('virtualenv',)\n",
      "PREDICTION: ('celery', 'django', 'virtualenv')\n",
      "\n",
      "First call to pytz.timezone is slow in virtualenv\n",
      "\n",
      "I have installed pytz (v2013.8, but it happens in 2013.b, 2011k) in a virtualenv.  The first call to \n",
      "pytz.timezone(\"US/Eastern\")\n",
      "\n",
      "takes about 4 seconds.  In a regular environment this is essentially instantaneous.  \n",
      "Does anyone have a trick to get this to run faster?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('bash', 'shell')\n",
      "PREDICTION: ('bash', 'shell')\n",
      "\n",
      "Is possible to create a shell like bash in python, ie: Bash replacement?\n",
      "\n",
      "I wonder if is possible to create a bash replacement but in python. I have done REPLs before, know about subprocess and that kind of stuff, but wonder how use my python-like-bash replacement in the OSX terminal as if were a native shell environment (with limitations). \n",
      "Or simply run ipython as is... \n",
      "P.D. The majority of the google answer are related to create shell scripts. I'm interested in create a shell..\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "How to make django task.py code editable in admin panel?\n",
      "\n",
      "I have some functions as tasks in my tasks.py file in django and I want to be able to edit the code of each task in my administration panel. Is there any way of doing this. If possible, I would also like to be able to add more tasks in my tasks.py file directly through administration panel without having to go into tasks.py file to add a new task function. If anyone can point me in the right direction, that would be really appreciated.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "django tenant schema example gives ImproperlyConfigured error\n",
      "\n",
      "I installed django tenent schema app using pip. \n",
      "Then downloaded the tenant example app form \"https://github.com/bernardopires/django-tenant-schemas/tree/master/examples/tenant_tutorial\".\n",
      "But when i try to run it I get following error \n",
      "django.core.exceptions.ImproperlyConfigured: Application labels aren't unique, duplicates: auth\n",
      "Any idea why that may be happening?\n",
      "python version 2.7\n",
      "django version 1.7.1\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('csv', 'file', 'parsing', 'string')\n",
      "PREDICTION: ('string',)\n",
      "\n",
      "Python String Manipulation\n",
      "\n",
      "I have a file that looks like the following. All I want is the Voltage, what is easiest way to strip everything else from it?\n",
      "Time,Voltage,Peak\n",
      "0.0,1.003911558621642,3\n",
      "0.00390625,1.0327467181982755,0\n",
      "0.0078125,0.9904463156237306,0\n",
      "0.01171875,0.6867661682528724,0\n",
      "0.015625,0.6236803073669519,0\n",
      "0.01953125,0.2934711210503298,0\n",
      "0.0234375,0.06148933838536881,0\n",
      "0.02734375,0.07053968550834916,0\n",
      "0.03125,-0.09041720958299812,0\n",
      "0.03515625,-0.28273374252040306,0\n",
      "0.0390625,-0.29775398016603216,0\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('mongodb',)\n",
      "PREDICTION: ()\n",
      "\n",
      "TypeError: documents must be a non-empty list\n",
      "\n",
      "I'm doing a program using Twitter API and MongoDB in 2.7 Python language.\n",
      "I get a timeline and put it in a dictionary, which I want to store in a MongoDB database. To do this I have next code:\n",
      "def saveOnBD(self, dic):\n",
      "    client = MongoClient(\"xxxx\", \"port\")\n",
      "    db = client.DB_Tweets_User_Date\n",
      "    collection = db.tweets\n",
      "    collection.insert_many(dic)\n",
      "\n",
      "I'm debbuging and dic it's not empty but I get next error:\n",
      "TypeError: documents must be a non-empty list\n",
      "\n",
      "How can I fix it?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('list', 'sorting')\n",
      "PREDICTION: ('list', 'sorting')\n",
      "\n",
      "sort float python list\n",
      "\n",
      "Here is my code:\n",
      "for line in lines:\n",
      "   name,price,yield = line.split(',')\n",
      "   for part in [price,yield]:\n",
      "       part = float(part)\n",
      "       company = Company(name,price,yield)\n",
      "\n",
      "tempList = sorted(companyList, key=lambda company: company.price)\n",
      "for company in tempList:\n",
      "    print(company.price)\n",
      "\n",
      "The printed list ranks 49.0 as smaller number than 5.0\n",
      "Does anybody know what is going wrong?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('matplotlib',)\n",
      "PREDICTION: ('matplotlib',)\n",
      "\n",
      "How can you clear a Matplotlib text box that was previously drawn?\n",
      "\n",
      "I can make text boxes in matplotlib fine.   But I dont see how to remove them from a rendered plot?  There seems to be no figure.text.clear() or figure.text(visible=False) after you draw a text box?  How is this done?  and unlike legends, you seem to be unable to make them draggable?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('osx',)\n",
      "PREDICTION: ('osx',)\n",
      "\n",
      "Two different Pythonpaths and how can I change them?\n",
      "\n",
      "Since I upgraded my Mac from Mountain Lion to Mavericks my Workflows from Automator and crontab don't work anymore. I found out, that the terminal normally uses a path within the /Library folder, while the Workflows and crontab use a path which begins with /System/Library. How can I change this path to the /Library-path? Because my modules are installed to this /Library path\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('python-2.7',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "setdefault() takes no keyword arguments\n",
      "\n",
      "I have the following code snippet:\n",
      "mirna2age = {}\n",
      "for i in agesdb:\n",
      "    mirna2age.setdefault(i[0],default=[]).append(i[1])\n",
      "\n",
      "However, Python returns \n",
      "TypeError: setdefault() takes no keyword arguments\n",
      "\n",
      "I am unsure why. Does anyone have any ideas?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('scikit-learn', 'scipy')\n",
      "PREDICTION: ('scipy',)\n",
      "\n",
      "Scipy: Speed up kernel density estimation's score_sample method?\n",
      "\n",
      "I'm trying to get the observed probability density using kernel density estimation. This is how I use the kde:\n",
      "from sklearn.neighbors import KernelDensity\n",
      "kde = KernelDensity().fit(sample)\n",
      "\n",
      "The problem is that, when I try to get the probability densitity of every point\n",
      "kde_result = kde.score_samples(sample)\n",
      "\n",
      "The speed is very slow. How can I speed it up?\n",
      "The sample is consist of 300,000 (x,y) points.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('numpy',)\n",
      "PREDICTION: ()\n",
      "\n",
      "How to read/extract climate model data in .asc file format by using Python?\n",
      "\n",
      "I have downloaded some global climate model data from an opensource website. But, these data are in .asc file format. How could I read/extract these data using Python? Anything in Numpy?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dictionary',)\n",
      "PREDICTION: ('dictionary',)\n",
      "\n",
      "create a copy of an existing dictionary but assign a unique ID for the copy\n",
      "\n",
      "I want to create a copy of a existing dict\n",
      "b = {'name':'someone'}\n",
      "copy_b = b\n",
      "\n",
      "if do this, changes made in copy_b will affect b,\n",
      "how can I make copy_b unique to b?\n",
      "Thanks,\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django', 'django-models', 'django-templates', 'django-views')\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "Filtering on foreign keys\n",
      "\n",
      "I generate QuerySet as follows:\n",
      "def get_queryset(self):\n",
      "    return Article.objects.filter(foreignkey=self.kwargs['value'])\n",
      "\n",
      "The value is generated like this:\n",
      "<a href=\"{% url 'someview' value %}\">anchor</a>\n",
      "url(r'^(?P<value>\\w+)/$', someview.as_view(), name='someview')\n",
      "\n",
      "When value is integer then everything works, but when I pass value as a string I receive:\n",
      "ValueError: \"invalid literal for int() with base 10\"\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('postgresql',)\n",
      "PREDICTION: ()\n",
      "\n",
      "openERP 7 need to export data in UTF-8 CSV , but how?\n",
      "\n",
      "I can export a CSV with openERP 7 , but it is encoded in ANSI. I would like to have it as a UTF-8 encoded file. How can I achieve this ? The default export option in openERP doesn\"t have any extra options. What files should be modified ? Or is there an app for this matter ? Any help would be appreciated.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('arrays',)\n",
      "PREDICTION: ('arrays', 'numpy')\n",
      "\n",
      "Get subarray from bi-dimensional array in just one line\n",
      "\n",
      "I have a problem trying to find and get and array from a bi dimensional array in python.\n",
      "I don't pretend to use a for structure for example in order to get this. Someone knows how to get this array in just one or a few lines of code?.\n",
      "Thanks.\n",
      "There is an example:\n",
      "my_dimensional_array = [(1,'a'),(1,'b'),(2,'c'))]\n",
      "\n",
      "I need to return\n",
      "my_single_array_from_1 = [(1,'a'),(1,'b')]\n",
      "\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('pandas',)\n",
      "PREDICTION: ('matplotlib', 'pandas')\n",
      "\n",
      "How to change the marker size in pandas.scatter_matrix?\n",
      "\n",
      "How to change the marker sizes in pandas.scatter_matrix() using python 3.5.2 and pandas 0.18.0? \n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('dataframe', 'pandas')\n",
      "PREDICTION: ('pandas',)\n",
      "\n",
      "How to get the first column of a pandas DataFrame as a Series?\n",
      "\n",
      "I tried:\n",
      "x=pandas.DataFrame(...)\n",
      "s = x.take([0], axis=1)\n",
      "\n",
      "And s gets a DataFrame, not a Series.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('regex',)\n",
      "PREDICTION: ('file',)\n",
      "\n",
      "modify text file\n",
      "\n",
      "I need to modify all files that has a \".txt\" extension within a directory in the following way:\n",
      "remove all text lines beginning with the line that starts with \"xxx\" and the line that ends with \"xxx\", inclusive.\n",
      "I know how to do this in Java or C++, but can someone show me a simple script that can get this done?\n",
      "Thanks!\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django', 'django-templates')\n",
      "\n",
      "Django template: Embed css from file\n",
      "\n",
      "I'm working on an email template, therefor I would like to embed a css file\n",
      "<head>\n",
      "   <style>{{ embed 'css/TEST.css' content here }}</style>\n",
      "</head>\n",
      "\n",
      "instead of linking it\n",
      "<head>\n",
      "   <link href=\"{% static 'css/TEST.css' %}\" rel=\"stylesheet\" type=\"text/css\">\n",
      "</head>\n",
      "\n",
      "Any ideas?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('selenium',)\n",
      "PREDICTION: ('selenium', 'windows')\n",
      "\n",
      "Python Chromedriver opens command prompt with browser\n",
      "\n",
      "I am on Windows and trying to run a pretty simple code:\n",
      "from selenium import webdriver\n",
      "\n",
      "chromedriver = '/path/to/chromedriver'\n",
      "driver = webdriver.Chrome(chromedriver)\n",
      "driver.get('https://www.google.com')\n",
      "\n",
      "For some reason when I run this code I will get the browser to open but the command prompt will open as well.  Did I do something wrong or is this supposed to happen?  How can I get it to only open the browser and not command prompt?\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('django',)\n",
      "PREDICTION: ('django',)\n",
      "\n",
      "django Search inside files\n",
      "\n",
      "I am building a file hosting application. I want to build a search form which can search inside static files (Something like grep). I have been through haystack but it didn't search inside static files. Is there any module for the same.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('osx', 'windows')\n",
      "PREDICTION: ('tkinter',)\n",
      "\n",
      "How does Dropbox use Python on Windows and OS X?\n",
      "\n",
      "In Windows the Dropbox client uses python25.dll and the MS C runtime libraries (msvcp71.dll, etc). On OS X the Python code is compiled bytecode (pyc).\n",
      "My guess is they are using a common library they have written then just have to use different hooks for the different platforms.\n",
      "What method of development is this? It clearly isn't IronPython or PyObjC. This paradigm is so appealing to me, but my CS foo and Google foo are failing me.\n",
      "\n",
      "--------------------------\n",
      "\n",
      "TRUE: ('numpy', 'scipy')\n",
      "PREDICTION: ('scipy',)\n",
      "\n",
      "interpolation of sparse grid using python (preferably scipy)\n",
      "\n",
      "I have a large (2000 x 2000) pixel grid that have values defined at only certain (x,y) coordinates. For example, a simplified version of this would look like this:\n",
      "-5-3--\n",
      "---0--\n",
      "-6--4-\n",
      "-4-5--\n",
      "---0--\n",
      "-6--4-\n",
      "\n",
      "How can I do linear interpolation or nearest neighbor interpolation so that I can have a defined value at every location in the grid.\n",
      "\n",
      "--------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([X_val_b, X_val_t])\n",
    "\n",
    "l_pred = label_encoder.inverse_transform(binarize_model_output(predictions, threshold=opt_thres))\n",
    "l_true = label_encoder.inverse_transform(y_val)\n",
    "raw_texts = validation_questions[content_field]\n",
    "titles = validation_questions[\"Title\"]\n",
    "\n",
    "for pred, act, raw_txt, title in zip(l_pred, l_true, raw_texts, titles):\n",
    "    print(f\"TRUE: {act}\\nPREDICTION: {pred}\\n\")\n",
    "    print(f\"{title}\\n\")\n",
    "    print(raw_txt)\n",
    "    print(f\"--------------------------\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
