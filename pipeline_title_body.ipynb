{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline using Title and Body Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "from toolbox.data_prep_helpers import *\n",
    "from toolbox.evaluation import *\n",
    "\n",
    "#from models.lstm_classifier import create_model\n",
    "from models.title_body_lstm import create_model as tb_create_model\n",
    "\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ModelCheckpoint\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, MultiLabelBinarizer\n",
    "import numpy as np\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../data/pythonquestions/\"\n",
    "ft_path = \"sg_model.ft\"  # set this to None if you want to train your own fasttext embeddings\n",
    "n_top_labels = 100\n",
    "n_epochs = 300\n",
    "max_question_words = 100\n",
    "sample_size = -1  # set to -1 to use entire data\n",
    "normalize_embeddings = True\n",
    "use_titles = False\n",
    "\n",
    "tokenized_field = \"q_all_body_tokenized\"\n",
    "content_field = \"Body_q\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\dschr\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data from cached pickle\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(607282, 5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data(data_path, ignore_cache=False, tokenized_field=tokenized_field, content_field=content_field)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body_q</th>\n",
       "      <th>tags</th>\n",
       "      <th>q_all_body_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>469</td>\n",
       "      <td>How can I find the full path to a font from it...</td>\n",
       "      <td>I am using the Photoshop's javascript API to f...</td>\n",
       "      <td>[python, osx, fonts, photoshop]</td>\n",
       "      <td>[i, am, using, the, photoshop, 's, javascript,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>502</td>\n",
       "      <td>Get a preview JPEG of a PDF on Windows?</td>\n",
       "      <td>I have a cross-platform (Python) application w...</td>\n",
       "      <td>[python, windows, image, pdf]</td>\n",
       "      <td>[i, have, a, cross-platform, (, python, ), app...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>535</td>\n",
       "      <td>Continuous Integration System for a Python Cod...</td>\n",
       "      <td>I'm starting work on a hobby project with a py...</td>\n",
       "      <td>[python, continuous-integration, extreme-progr...</td>\n",
       "      <td>[i, 'm, starting, work, on, a, hobby, project,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>594</td>\n",
       "      <td>cx_Oracle: How do I iterate over a result set?</td>\n",
       "      <td>There are several ways to iterate over a resul...</td>\n",
       "      <td>[python, sql, database, oracle, cx-oracle]</td>\n",
       "      <td>[there, are, several, ways, to, iterate, over,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>683</td>\n",
       "      <td>Using 'in' to match an attribute of Python obj...</td>\n",
       "      <td>I don't remember whether I was dreaming or not...</td>\n",
       "      <td>[python, arrays, iteration]</td>\n",
       "      <td>[i, do, n't, remember, whether, i, was, dreami...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id                                              Title  \\\n",
       "0  469  How can I find the full path to a font from it...   \n",
       "1  502            Get a preview JPEG of a PDF on Windows?   \n",
       "2  535  Continuous Integration System for a Python Cod...   \n",
       "3  594     cx_Oracle: How do I iterate over a result set?   \n",
       "4  683  Using 'in' to match an attribute of Python obj...   \n",
       "\n",
       "                                              Body_q  \\\n",
       "0  I am using the Photoshop's javascript API to f...   \n",
       "1  I have a cross-platform (Python) application w...   \n",
       "2  I'm starting work on a hobby project with a py...   \n",
       "3  There are several ways to iterate over a resul...   \n",
       "4  I don't remember whether I was dreaming or not...   \n",
       "\n",
       "                                                tags  \\\n",
       "0                    [python, osx, fonts, photoshop]   \n",
       "1                      [python, windows, image, pdf]   \n",
       "2  [python, continuous-integration, extreme-progr...   \n",
       "3         [python, sql, database, oracle, cx-oracle]   \n",
       "4                        [python, arrays, iteration]   \n",
       "\n",
       "                                q_all_body_tokenized  \n",
       "0  [i, am, using, the, photoshop, 's, javascript,...  \n",
       "1  [i, have, a, cross-platform, (, python, ), app...  \n",
       "2  [i, 'm, starting, work, on, a, hobby, project,...  \n",
       "3  [there, are, several, ways, to, iterate, over,...  \n",
       "4  [i, do, n't, remember, whether, i, was, dreami...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = df.sample(sample_size) if sample_size > 0 else df\n",
    "del df\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove_html_tags(chunk, [\"Body_q\"])\n",
    "#print(f\"{i}: generating question level tokens\")\n",
    "sample[\"q_title_tokenized\"] = sample[\"Title\"].apply(generate_question_level_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(607282, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(607282, 6)\n",
      "(606841, 6)\n",
      "deleting element python from top_tags\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(425658, 6)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we have some nans in our tags which break target encoding\n",
    "print(sample.shape)\n",
    "sample = sample[sample[\"tags\"].apply(lambda tags: all([isinstance(t, str) for t in tags]))]\n",
    "print(sample.shape)\n",
    "\n",
    "\n",
    "# Reduce the number of tags and adjust dataframe accordingly\n",
    "sample = reduce_number_of_tags(sample, n_top_labels)\n",
    "sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0               [osx]\n",
       "1    [windows, image]\n",
       "3     [sql, database]\n",
       "4            [arrays]\n",
       "5       [django, oop]\n",
       "Name: tags, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"tags\"].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Training and Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize text into words on question level\n",
    "data = sample[sample[tokenized_field].apply(len) <= max_question_words]\n",
    "data = data[data[\"q_all_body_tokenized\"].apply(len) > 0]\n",
    "\n",
    "# train_data, test_data = train_test_split(data, test_size = 0.2)\n",
    "# print(train_data.shape)\n",
    "# print(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(97627, 6)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word embeddings ONLY with training data\n",
    "# wv = create_Word2Vec_embeddings(train_data, \"Body_q\")\n",
    "# Use FastText to include solution for out-of-vocab words\n",
    "if ft_path is not None:\n",
    "    wv = load_fasttext_embeddings(ft_path)\n",
    "else:\n",
    "    wv = create_FastText_embeddings(df, content_field)   \n",
    "wv.init_sims()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Title and Body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(97627, 40, 100)\n",
      "(97627, 100, 100)\n",
      "(97627, 100)\n"
     ]
    }
   ],
   "source": [
    "X_t = data[\"q_title_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))\n",
    "X_b = data[\"q_all_body_tokenized\"].apply(lambda x: np.array([wv.word_vec(w, use_norm=normalize_embeddings) for w in x]))\n",
    "\n",
    "padding_element = np.array([0.0] * X_t.iloc[0].shape[-1])\n",
    "\n",
    "X_t = pad_sequences(X_t, padding=\"post\", dtype='float32', value=padding_element)\n",
    "X_b = pad_sequences(X_b, padding=\"post\", dtype='float32', value=padding_element)\n",
    "print(X_t.shape)\n",
    "print(X_b.shape)\n",
    "\n",
    "label_encoder = MultiLabelBinarizer()\n",
    "label_encoder.fit(data[\"tags\"])\n",
    "y = label_encoder.transform(data[\"tags\"])\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lstm_layer_size': 256, 'lstm_dropout': 0.0, 'num_mid_dense': 1, 'output_dim': 100}\n",
      "Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 2:55:13 - loss: 0.6937 - accuracy: 0.4856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:27 - loss: 0.6848 - accuracy: 0.6695 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:45 - loss: 0.6737 - accuracy: 0.7305 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 27:53 - loss: 0.6564 - accuracy: 0.7659 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:16 - loss: 0.6281 - accuracy: 0.7881 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:07 - loss: 0.5707 - accuracy: 0.8048 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 26:31 - loss: 0.4882 - accuracy: 0.8225 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 26:23 - loss: 0.4071 - accuracy: 0.8328 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 26:12 - loss: 0.3469 - accuracy: 0.8513 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 26:17 - loss: 0.2905 - accuracy: 0.8798 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 26:45 - loss: 0.2446 - accuracy: 0.9180 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 27:15 - loss: 0.2001 - accuracy: 0.9499 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 27:24 - loss: 0.1653 - accuracy: 0.9630 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 28:40 - loss: 0.1392 - accuracy: 0.9677 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 28:18 - loss: 0.1204 - accuracy: 0.9723 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 28:22 - loss: 0.1079 - accuracy: 0.9763 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 28:44 - loss: 0.0877 - accuracy: 0.9876 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 28:11 - loss: 0.0959 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 28:07 - loss: 0.0870 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 27:25 - loss: 0.0862 - accuracy: 0.9851 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 28:16 - loss: 0.0843 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 28:20 - loss: 0.0793 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 28:22 - loss: 0.0919 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 29:20 - loss: 0.0934 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 25/150\n",
      "  128/78101 [..............................] - ETA: 28:53 - loss: 0.0798 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 26/150\n",
      "  128/78101 [..............................] - ETA: 28:49 - loss: 0.0854 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 27/150\n",
      "  128/78101 [..............................] - ETA: 28:49 - loss: 0.0764 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 28/150\n",
      "  128/78101 [..............................] - ETA: 28:40 - loss: 0.0727 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 29/150\n",
      "  128/78101 [..............................] - ETA: 28:01 - loss: 0.0792 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 30/150\n",
      "  128/78101 [..............................] - ETA: 28:10 - loss: 0.0800 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 31/150\n",
      "  128/78101 [..............................] - ETA: 28:12 - loss: 0.0825 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 32/150\n",
      "  128/78101 [..............................] - ETA: 28:31 - loss: 0.0764 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 33/150\n",
      "  128/78101 [..............................] - ETA: 29:33 - loss: 0.0785 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 34/150\n",
      "  128/78101 [..............................] - ETA: 28:46 - loss: 0.0767 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 35/150\n",
      "  128/78101 [..............................] - ETA: 29:40 - loss: 0.0712 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 36/150\n",
      "  128/78101 [..............................] - ETA: 28:06 - loss: 0.0707 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 37/150\n",
      "  128/78101 [..............................] - ETA: 29:29 - loss: 0.0712 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 38/150\n",
      "  128/78101 [..............................] - ETA: 28:55 - loss: 0.0708 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 39/150\n",
      "  128/78101 [..............................] - ETA: 28:59 - loss: 0.0726 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 40/150\n",
      "  128/78101 [..............................] - ETA: 30:03 - loss: 0.0704 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 41/150\n",
      "  128/78101 [..............................] - ETA: 28:37 - loss: 0.0655 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 42/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.0651 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 43/150\n",
      "  128/78101 [..............................] - ETA: 29:35 - loss: 0.0662 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 44/150\n",
      "  128/78101 [..............................] - ETA: 29:04 - loss: 0.0708 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 45/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0693 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 46/150\n",
      "  128/78101 [..............................] - ETA: 29:09 - loss: 0.0745 - accuracy: 0.9854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 47/150\n",
      "  128/78101 [..............................] - ETA: 29:29 - loss: 0.0707 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 48/150\n",
      "  128/78101 [..............................] - ETA: 29:21 - loss: 0.0643 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 49/150\n",
      "  128/78101 [..............................] - ETA: 29:24 - loss: 0.0686 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 50/150\n",
      "  128/78101 [..............................] - ETA: 29:13 - loss: 0.0651 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 51/150\n",
      "  128/78101 [..............................] - ETA: 29:36 - loss: 0.0675 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 52/150\n",
      "  128/78101 [..............................] - ETA: 30:55 - loss: 0.0639 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 53/150\n",
      "  128/78101 [..............................] - ETA: 31:22 - loss: 0.0694 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 54/150\n",
      "  128/78101 [..............................] - ETA: 31:20 - loss: 0.0663 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 55/150\n",
      "  128/78101 [..............................] - ETA: 31:14 - loss: 0.0659 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 56/150\n",
      "  128/78101 [..............................] - ETA: 30:24 - loss: 0.0680 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 57/150\n",
      "  128/78101 [..............................] - ETA: 29:31 - loss: 0.0666 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 58/150\n",
      "  128/78101 [..............................] - ETA: 29:26 - loss: 0.0653 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 59/150\n",
      "  128/78101 [..............................] - ETA: 30:44 - loss: 0.0646 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 60/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.0656 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 61/150\n",
      "  128/78101 [..............................] - ETA: 30:45 - loss: 0.0689 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 62/150\n",
      "  128/78101 [..............................] - ETA: 30:09 - loss: 0.0638 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 63/150\n",
      "  128/78101 [..............................] - ETA: 32:30 - loss: 0.0635 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 64/150\n",
      "  128/78101 [..............................] - ETA: 30:32 - loss: 0.0697 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 65/150\n",
      "  128/78101 [..............................] - ETA: 30:21 - loss: 0.0669 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 66/150\n",
      "  128/78101 [..............................] - ETA: 30:10 - loss: 0.0682 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 67/150\n",
      "  128/78101 [..............................] - ETA: 30:01 - loss: 0.0655 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 68/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0655 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 69/150\n",
      "  128/78101 [..............................] - ETA: 29:59 - loss: 0.0619 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 70/150\n",
      "  128/78101 [..............................] - ETA: 30:17 - loss: 0.0676 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 71/150\n",
      "  128/78101 [..............................] - ETA: 29:53 - loss: 0.0634 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 72/150\n",
      "  128/78101 [..............................] - ETA: 30:12 - loss: 0.0703 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 73/150\n",
      "  128/78101 [..............................] - ETA: 30:22 - loss: 0.0650 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 74/150\n",
      "  128/78101 [..............................] - ETA: 32:17 - loss: 0.0643 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 75/150\n",
      "  128/78101 [..............................] - ETA: 30:41 - loss: 0.0648 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 76/150\n",
      "  128/78101 [..............................] - ETA: 30:10 - loss: 0.0659 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 77/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0710 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 78/150\n",
      "  128/78101 [..............................] - ETA: 29:59 - loss: 0.0686 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 79/150\n",
      "  128/78101 [..............................] - ETA: 30:32 - loss: 0.0698 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 80/150\n",
      "  128/78101 [..............................] - ETA: 31:50 - loss: 0.0691 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 81/150\n",
      "  128/78101 [..............................] - ETA: 33:00 - loss: 0.0692 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 82/150\n",
      "  128/78101 [..............................] - ETA: 30:57 - loss: 0.0653 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 83/150\n",
      "  128/78101 [..............................] - ETA: 32:16 - loss: 0.0670 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 84/150\n",
      "  128/78101 [..............................] - ETA: 34:13 - loss: 0.0679 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 85/150\n",
      "  128/78101 [..............................] - ETA: 30:40 - loss: 0.0650 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 86/150\n",
      "  128/78101 [..............................] - ETA: 31:06 - loss: 0.0674 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 87/150\n",
      "  128/78101 [..............................] - ETA: 30:43 - loss: 0.0640 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 88/150\n",
      "  128/78101 [..............................] - ETA: 30:43 - loss: 0.0650 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 89/150\n",
      "  128/78101 [..............................] - ETA: 30:42 - loss: 0.0622 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 90/150\n",
      "  128/78101 [..............................] - ETA: 30:36 - loss: 0.0690 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 91/150\n",
      "  128/78101 [..............................] - ETA: 30:53 - loss: 0.0686 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 92/150\n",
      "  128/78101 [..............................] - ETA: 31:39 - loss: 0.0642 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 93/150\n",
      "  128/78101 [..............................] - ETA: 31:54 - loss: 0.0658 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 94/150\n",
      "  128/78101 [..............................] - ETA: 31:55 - loss: 0.0637 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 95/150\n",
      "  128/78101 [..............................] - ETA: 31:42 - loss: 0.0643 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 96/150\n",
      "  128/78101 [..............................] - ETA: 32:07 - loss: 0.0598 - accuracy: 0.9879 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 97/150\n",
      "  128/78101 [..............................] - ETA: 31:33 - loss: 0.0686 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 98/150\n",
      "  128/78101 [..............................] - ETA: 30:02 - loss: 0.0694 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 3:22:28 - loss: 0.6940 - accuracy: 0.5190 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 27:23 - loss: 0.6854 - accuracy: 0.6717 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:49 - loss: 0.6751 - accuracy: 0.7272 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:15 - loss: 0.6587 - accuracy: 0.7533 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:42 - loss: 0.6321 - accuracy: 0.7677 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:48 - loss: 0.5771 - accuracy: 0.7856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 28:28 - loss: 0.4874 - accuracy: 0.8058 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 28:02 - loss: 0.4053 - accuracy: 0.8394 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 29:48 - loss: 0.3362 - accuracy: 0.8685 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 29:39 - loss: 0.2840 - accuracy: 0.9289 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 29:01 - loss: 0.2324 - accuracy: 0.9447 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.1863 - accuracy: 0.9596 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 29:18 - loss: 0.1537 - accuracy: 0.9770 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 30:27 - loss: 0.1281 - accuracy: 0.9785 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 30:11 - loss: 0.1126 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 30:34 - loss: 0.0944 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 30:20 - loss: 0.0934 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 30:08 - loss: 0.0949 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 30:23 - loss: 0.0887 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0916 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 30:19 - loss: 0.0885 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 30:03 - loss: 0.0861 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0784 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 30:25 - loss: 0.0813 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 25/150\n",
      "  128/78101 [..............................] - ETA: 32:26 - loss: 0.0832 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 26/150\n",
      "  128/78101 [..............................] - ETA: 32:39 - loss: 0.0755 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 27/150\n",
      "  128/78101 [..............................] - ETA: 30:33 - loss: 0.0769 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 28/150\n",
      "  128/78101 [..............................] - ETA: 30:51 - loss: 0.0760 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 29/150\n",
      "  128/78101 [..............................] - ETA: 32:01 - loss: 0.0739 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 30/150\n",
      "  128/78101 [..............................] - ETA: 31:12 - loss: 0.0799 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 31/150\n",
      "  128/78101 [..............................] - ETA: 33:49 - loss: 0.0757 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 32/150\n",
      "  128/78101 [..............................] - ETA: 32:01 - loss: 0.0795 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 33/150\n",
      "  128/78101 [..............................] - ETA: 31:14 - loss: 0.0723 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 34/150\n",
      "  128/78101 [..............................] - ETA: 31:00 - loss: 0.0736 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 35/150\n",
      "  128/78101 [..............................] - ETA: 31:16 - loss: 0.0739 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 36/150\n",
      "  128/78101 [..............................] - ETA: 31:07 - loss: 0.0667 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 37/150\n",
      "  128/78101 [..............................] - ETA: 31:25 - loss: 0.0746 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 38/150\n",
      "  128/78101 [..............................] - ETA: 31:21 - loss: 0.0653 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 39/150\n",
      "  128/78101 [..............................] - ETA: 31:18 - loss: 0.0682 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 40/150\n",
      "  128/78101 [..............................] - ETA: 31:16 - loss: 0.0615 - accuracy: 0.9877 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 41/150\n",
      "  128/78101 [..............................] - ETA: 31:07 - loss: 0.0711 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 42/150\n",
      "  128/78101 [..............................] - ETA: 31:16 - loss: 0.0672 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 43/150\n",
      "  128/78101 [..............................] - ETA: 30:55 - loss: 0.0678 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 44/150\n",
      "  128/78101 [..............................] - ETA: 31:17 - loss: 0.0659 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 45/150\n",
      "  128/78101 [..............................] - ETA: 31:13 - loss: 0.0672 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 46/150\n",
      "  128/78101 [..............................] - ETA: 30:57 - loss: 0.0680 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 47/150\n",
      "  128/78101 [..............................] - ETA: 31:20 - loss: 0.0697 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 48/150\n",
      "  128/78101 [..............................] - ETA: 31:04 - loss: 0.0672 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 49/150\n",
      "  128/78101 [..............................] - ETA: 31:13 - loss: 0.0665 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 50/150\n",
      "  128/78101 [..............................] - ETA: 30:55 - loss: 0.0637 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 51/150\n",
      "  128/78101 [..............................] - ETA: 31:17 - loss: 0.0713 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 52/150\n",
      "  128/78101 [..............................] - ETA: 31:10 - loss: 0.0713 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 53/150\n",
      "  128/78101 [..............................] - ETA: 31:04 - loss: 0.0710 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 54/150\n",
      "  128/78101 [..............................] - ETA: 31:09 - loss: 0.0685 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 55/150\n",
      "  128/78101 [..............................] - ETA: 30:52 - loss: 0.0683 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 56/150\n",
      "  128/78101 [..............................] - ETA: 31:23 - loss: 0.0696 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 57/150\n",
      "  128/78101 [..............................] - ETA: 30:57 - loss: 0.0696 - accuracy: 0.9854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 58/150\n",
      "  128/78101 [..............................] - ETA: 31:18 - loss: 0.0671 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 59/150\n",
      "  128/78101 [..............................] - ETA: 31:15 - loss: 0.0631 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 60/150\n",
      "  128/78101 [..............................] - ETA: 31:20 - loss: 0.0738 - accuracy: 0.9851 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 61/150\n",
      "  128/78101 [..............................] - ETA: 31:14 - loss: 0.0697 - accuracy: 0.9854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 62/150\n",
      "  128/78101 [..............................] - ETA: 30:58 - loss: 0.0686 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 63/150\n",
      "  128/78101 [..............................] - ETA: 31:09 - loss: 0.0659 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 64/150\n",
      "  128/78101 [..............................] - ETA: 30:54 - loss: 0.0659 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 65/150\n",
      "  128/78101 [..............................] - ETA: 31:15 - loss: 0.0689 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 66/150\n",
      "  128/78101 [..............................] - ETA: 31:45 - loss: 0.0673 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 67/150\n",
      "  128/78101 [..............................] - ETA: 33:12 - loss: 0.0691 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 68/150\n",
      "  128/78101 [..............................] - ETA: 36:53 - loss: 0.0716 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 69/150\n",
      "  128/78101 [..............................] - ETA: 35:04 - loss: 0.0642 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 70/150\n",
      "  128/78101 [..............................] - ETA: 31:35 - loss: 0.0677 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 71/150\n",
      "  128/78101 [..............................] - ETA: 31:17 - loss: 0.0661 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 72/150\n",
      "  128/78101 [..............................] - ETA: 31:46 - loss: 0.0647 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 73/150\n",
      "  128/78101 [..............................] - ETA: 31:25 - loss: 0.0647 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 74/150\n",
      "  128/78101 [..............................] - ETA: 31:20 - loss: 0.0651 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 75/150\n",
      "  128/78101 [..............................] - ETA: 31:36 - loss: 0.0681 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 76/150\n",
      "  128/78101 [..............................] - ETA: 44:27 - loss: 0.0714 - accuracy: 0.9849 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 77/150\n",
      "  128/78101 [..............................] - ETA: 32:03 - loss: 0.0639 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 78/150\n",
      "  128/78101 [..............................] - ETA: 30:20 - loss: 0.0642 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 79/150\n",
      "  128/78101 [..............................] - ETA: 30:59 - loss: 0.0645 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 80/150\n",
      "  128/78101 [..............................] - ETA: 34:57 - loss: 0.0657 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 81/150\n",
      "  128/78101 [..............................] - ETA: 34:36 - loss: 0.0662 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 82/150\n",
      "  128/78101 [..............................] - ETA: 35:04 - loss: 0.0683 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 83/150\n",
      "  128/78101 [..............................] - ETA: 34:46 - loss: 0.0647 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 84/150\n",
      "  128/78101 [..............................] - ETA: 34:51 - loss: 0.0677 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 85/150\n",
      "  128/78101 [..............................] - ETA: 34:51 - loss: 0.0627 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 86/150\n",
      "  128/78101 [..............................] - ETA: 34:32 - loss: 0.0650 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 87/150\n",
      "  128/78101 [..............................] - ETA: 34:11 - loss: 0.0682 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 88/150\n",
      "  128/78101 [..............................] - ETA: 34:01 - loss: 0.0658 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 89/150\n",
      "  128/78101 [..............................] - ETA: 34:02 - loss: 0.0670 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 90/150\n",
      "  128/78101 [..............................] - ETA: 32:47 - loss: 0.0673 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00average min val_loss: 0.06622259205196354 -- epochs: [98, 90] -- time: 1027.04 seconds\n",
      "{'lstm_layer_size': 256, 'lstm_dropout': 0.0, 'num_mid_dense': 0, 'output_dim': 100}\n",
      "Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 3:17:12 - loss: 0.6932 - accuracy: 0.5040 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:25 - loss: 0.6757 - accuracy: 0.8187 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:22 - loss: 0.6561 - accuracy: 0.9199 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:30 - loss: 0.6233 - accuracy: 0.9537 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:11 - loss: 0.5576 - accuracy: 0.9650 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:25 - loss: 0.4359 - accuracy: 0.9718 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 26:59 - loss: 0.3306 - accuracy: 0.9768 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 27:23 - loss: 0.2472 - accuracy: 0.9816 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 27:38 - loss: 0.1895 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 28:26 - loss: 0.1393 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 28:54 - loss: 0.1106 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 28:40 - loss: 0.0876 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 29:07 - loss: 0.0795 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 28:29 - loss: 0.0757 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0799 - accuracy: 0.9853 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 29:39 - loss: 0.0772 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 29:45 - loss: 0.0785 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 29:29 - loss: 0.0789 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 29:37 - loss: 0.0761 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 30:49 - loss: 0.0798 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 31:47 - loss: 0.0865 - accuracy: 0.9851 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 30:09 - loss: 0.0828 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 29:30 - loss: 0.0799 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 30:45 - loss: 0.0760 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 69:43:39 - loss: 0.6947 - accuracy: 0.4802 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:39 - loss: 0.6787 - accuracy: 0.7405 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:12 - loss: 0.6612 - accuracy: 0.8834 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:16 - loss: 0.6342 - accuracy: 0.9520 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 25:31 - loss: 0.5913 - accuracy: 0.9661 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:07 - loss: 0.4979 - accuracy: 0.9750 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 26:30 - loss: 0.3785 - accuracy: 0.9827 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 26:24 - loss: 0.2801 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 27:05 - loss: 0.2133 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 26:35 - loss: 0.1536 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 27:57 - loss: 0.1209 - accuracy: 0.9854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 28:48 - loss: 0.0957 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 30:08 - loss: 0.0811 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 30:02 - loss: 0.0771 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 28:54 - loss: 0.0769 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 28:41 - loss: 0.0805 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 28:12 - loss: 0.0711 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 28:21 - loss: 0.0755 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 28:09 - loss: 0.0758 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 28:47 - loss: 0.0740 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 29:15 - loss: 0.0807 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 29:04 - loss: 0.0795 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 28:00 - loss: 0.0863 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 29:15 - loss: 0.0824 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00average min val_loss: 0.07582464436620312 -- epochs: [24, 24] -- time: 687.41 seconds\n",
      "{'lstm_layer_size': 256, 'lstm_dropout': 0.2, 'num_mid_dense': 1, 'output_dim': 100}\n",
      "Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 3:39:43 - loss: 0.6933 - accuracy: 0.4865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:27 - loss: 0.6818 - accuracy: 0.7081 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:52 - loss: 0.6672 - accuracy: 0.7893 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:41 - loss: 0.6451 - accuracy: 0.8172 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:48 - loss: 0.6082 - accuracy: 0.8267 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:46 - loss: 0.5364 - accuracy: 0.8342 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 26:27 - loss: 0.4435 - accuracy: 0.8516 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 26:51 - loss: 0.3723 - accuracy: 0.8638 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 26:37 - loss: 0.3176 - accuracy: 0.8869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 27:03 - loss: 0.2687 - accuracy: 0.9161 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 27:31 - loss: 0.2312 - accuracy: 0.9434 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 27:13 - loss: 0.1946 - accuracy: 0.9527 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 27:57 - loss: 0.1690 - accuracy: 0.9663 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 27:34 - loss: 0.1410 - accuracy: 0.9666 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 27:41 - loss: 0.1227 - accuracy: 0.9763 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 28:54 - loss: 0.0962 - accuracy: 0.9777 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 27:57 - loss: 0.0894 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 28:46 - loss: 0.0850 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 29:18 - loss: 0.0862 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 28:33 - loss: 0.0821 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 28:30 - loss: 0.0825 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 29:12 - loss: 0.0816 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 29:15 - loss: 0.0832 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 29:11 - loss: 0.0789 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 25/150\n",
      "  128/78101 [..............................] - ETA: 29:19 - loss: 0.0826 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 26/150\n",
      "  128/78101 [..............................] - ETA: 29:20 - loss: 0.0804 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 27/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0749 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 28/150\n",
      "  128/78101 [..............................] - ETA: 28:52 - loss: 0.0772 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 29/150\n",
      "  128/78101 [..............................] - ETA: 30:27 - loss: 0.0717 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 30/150\n",
      "  128/78101 [..............................] - ETA: 29:22 - loss: 0.0758 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 31/150\n",
      "  128/78101 [..............................] - ETA: 29:48 - loss: 0.0771 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 32/150\n",
      "  128/78101 [..............................] - ETA: 30:50 - loss: 0.0773 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 33/150\n",
      "  128/78101 [..............................] - ETA: 29:13 - loss: 0.0725 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 34/150\n",
      "  128/78101 [..............................] - ETA: 30:25 - loss: 0.0780 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 35/150\n",
      "  128/78101 [..............................] - ETA: 29:16 - loss: 0.0792 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 36/150\n",
      "  128/78101 [..............................] - ETA: 29:24 - loss: 0.0690 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 37/150\n",
      "  128/78101 [..............................] - ETA: 29:02 - loss: 0.0699 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 38/150\n",
      "  128/78101 [..............................] - ETA: 30:53 - loss: 0.0718 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 39/150\n",
      "  128/78101 [..............................] - ETA: 30:25 - loss: 0.0753 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 40/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.0666 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 41/150\n",
      "  128/78101 [..............................] - ETA: 30:02 - loss: 0.0705 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 42/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0654 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 43/150\n",
      "  128/78101 [..............................] - ETA: 30:20 - loss: 0.0673 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 44/150\n",
      "  128/78101 [..............................] - ETA: 29:53 - loss: 0.0676 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 45/150\n",
      "  128/78101 [..............................] - ETA: 30:20 - loss: 0.0675 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 46/150\n",
      "  128/78101 [..............................] - ETA: 30:18 - loss: 0.0684 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 47/150\n",
      "  128/78101 [..............................] - ETA: 29:56 - loss: 0.0693 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 48/150\n",
      "  128/78101 [..............................] - ETA: 30:23 - loss: 0.0702 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 49/150\n",
      "  128/78101 [..............................] - ETA: 29:58 - loss: 0.0680 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 50/150\n",
      "  128/78101 [..............................] - ETA: 30:13 - loss: 0.0666 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 51/150\n",
      "  128/78101 [..............................] - ETA: 30:01 - loss: 0.0676 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 52/150\n",
      "  128/78101 [..............................] - ETA: 30:11 - loss: 0.0645 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 53/150\n",
      "  128/78101 [..............................] - ETA: 30:10 - loss: 0.0666 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 54/150\n",
      "  128/78101 [..............................] - ETA: 29:57 - loss: 0.0624 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 55/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0753 - accuracy: 0.9846 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 56/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0721 - accuracy: 0.9854 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 57/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0697 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 58/150\n",
      "  128/78101 [..............................] - ETA: 30:06 - loss: 0.0665 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 59/150\n",
      "  128/78101 [..............................] - ETA: 30:12 - loss: 0.0670 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 60/150\n",
      "  128/78101 [..............................] - ETA: 30:22 - loss: 0.0656 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 61/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.0640 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 62/150\n",
      "  128/78101 [..............................] - ETA: 29:54 - loss: 0.0648 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 63/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.0671 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 64/150\n",
      "  128/78101 [..............................] - ETA: 30:03 - loss: 0.0670 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 65/150\n",
      "  128/78101 [..............................] - ETA: 30:00 - loss: 0.0683 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 66/150\n",
      "  128/78101 [..............................] - ETA: 30:18 - loss: 0.0653 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 67/150\n",
      "  128/78101 [..............................] - ETA: 30:35 - loss: 0.0702 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 68/150\n",
      "  128/78101 [..............................] - ETA: 32:01 - loss: 0.0658 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 69/150\n",
      "  128/78101 [..............................] - ETA: 33:34 - loss: 0.0647 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 70/150\n",
      "  128/78101 [..............................] - ETA: 31:07 - loss: 0.0683 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 71/150\n",
      "  128/78101 [..............................] - ETA: 30:33 - loss: 0.0700 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 72/150\n",
      "  128/78101 [..............................] - ETA: 30:17 - loss: 0.0651 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 73/150\n",
      "  128/78101 [..............................] - ETA: 30:34 - loss: 0.0700 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 74/150\n",
      "  128/78101 [..............................] - ETA: 30:29 - loss: 0.0659 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 75/150\n",
      "  128/78101 [..............................] - ETA: 30:11 - loss: 0.0659 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 76/150\n",
      "  128/78101 [..............................] - ETA: 30:24 - loss: 0.0637 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 77/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0658 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 78/150\n",
      "  128/78101 [..............................] - ETA: 30:21 - loss: 0.0661 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 79/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0722 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 80/150\n",
      "  128/78101 [..............................] - ETA: 30:38 - loss: 0.0644 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 81/150\n",
      "  128/78101 [..............................] - ETA: 30:29 - loss: 0.0687 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 82/150\n",
      "  128/78101 [..............................] - ETA: 30:12 - loss: 0.0652 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 83/150\n",
      "  128/78101 [..............................] - ETA: 30:36 - loss: 0.0667 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 84/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0701 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 85/150\n",
      "  128/78101 [..............................] - ETA: 30:33 - loss: 0.0650 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 86/150\n",
      "  128/78101 [..............................] - ETA: 30:11 - loss: 0.0667 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 87/150\n",
      "  128/78101 [..............................] - ETA: 30:37 - loss: 0.0650 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 88/150\n",
      "  128/78101 [..............................] - ETA: 30:30 - loss: 0.0679 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 89/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0695 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 90/150\n",
      "  128/78101 [..............................] - ETA: 30:30 - loss: 0.0638 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 91/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0689 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 92/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0680 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 93/150\n",
      "  128/78101 [..............................] - ETA: 30:25 - loss: 0.0668 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 94/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0671 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 95/150\n",
      "  128/78101 [..............................] - ETA: 32:17 - loss: 0.0638 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 96/150\n",
      "  128/78101 [..............................] - ETA: 29:56 - loss: 0.0662 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 3:37:17 - loss: 0.6929 - accuracy: 0.5249 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:12 - loss: 0.6837 - accuracy: 0.7160 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:37 - loss: 0.6722 - accuracy: 0.7866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:29 - loss: 0.6529 - accuracy: 0.8283 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:54 - loss: 0.6194 - accuracy: 0.8352 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 26:25 - loss: 0.5509 - accuracy: 0.8409 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 26:08 - loss: 0.4547 - accuracy: 0.8552 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 26:43 - loss: 0.3722 - accuracy: 0.8896 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 26:19 - loss: 0.3019 - accuracy: 0.9101 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 27:13 - loss: 0.2391 - accuracy: 0.9395 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 27:33 - loss: 0.1855 - accuracy: 0.9478 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 27:39 - loss: 0.1484 - accuracy: 0.9666 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 28:35 - loss: 0.1144 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 28:00 - loss: 0.0952 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 28:47 - loss: 0.0861 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 28:54 - loss: 0.0875 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 29:21 - loss: 0.0836 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 29:35 - loss: 0.0843 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 29:30 - loss: 0.0910 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 29:30 - loss: 0.0824 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 29:20 - loss: 0.0843 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 29:40 - loss: 0.0859 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 29:23 - loss: 0.0853 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 29:41 - loss: 0.0831 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 25/150\n",
      "  128/78101 [..............................] - ETA: 29:19 - loss: 0.0890 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 26/150\n",
      "  128/78101 [..............................] - ETA: 31:16 - loss: 0.0766 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 27/150\n",
      "  128/78101 [..............................] - ETA: 30:31 - loss: 0.0776 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 28/150\n",
      "  128/78101 [..............................] - ETA: 29:56 - loss: 0.0779 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 29/150\n",
      "  128/78101 [..............................] - ETA: 30:56 - loss: 0.0822 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 30/150\n",
      "  128/78101 [..............................] - ETA: 31:06 - loss: 0.0709 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 31/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0759 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 32/150\n",
      "  128/78101 [..............................] - ETA: 31:42 - loss: 0.0688 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 33/150\n",
      "  128/78101 [..............................] - ETA: 31:19 - loss: 0.0750 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 34/150\n",
      "  128/78101 [..............................] - ETA: 30:19 - loss: 0.0716 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 35/150\n",
      "  128/78101 [..............................] - ETA: 29:54 - loss: 0.0710 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 36/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0710 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 37/150\n",
      "  128/78101 [..............................] - ETA: 29:54 - loss: 0.0738 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 38/150\n",
      "  128/78101 [..............................] - ETA: 30:19 - loss: 0.0702 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 39/150\n",
      "  128/78101 [..............................] - ETA: 29:59 - loss: 0.0730 - accuracy: 0.9851 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 40/150\n",
      "  128/78101 [..............................] - ETA: 30:10 - loss: 0.0670 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 41/150\n",
      "  128/78101 [..............................] - ETA: 30:15 - loss: 0.0683 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 42/150\n",
      "  128/78101 [..............................] - ETA: 31:45 - loss: 0.0656 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 43/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0649 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 44/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0690 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 45/150\n",
      "  128/78101 [..............................] - ETA: 30:20 - loss: 0.0717 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 46/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0712 - accuracy: 0.9853 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 47/150\n",
      "  128/78101 [..............................] - ETA: 30:14 - loss: 0.0676 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 48/150\n",
      "  128/78101 [..............................] - ETA: 31:54 - loss: 0.0647 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 49/150\n",
      "  128/78101 [..............................] - ETA: 31:53 - loss: 0.0664 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 50/150\n",
      "  128/78101 [..............................] - ETA: 30:27 - loss: 0.0681 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 51/150\n",
      "  128/78101 [..............................] - ETA: 30:24 - loss: 0.0644 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 52/150\n",
      "  128/78101 [..............................] - ETA: 30:27 - loss: 0.0670 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 53/150\n",
      "  128/78101 [..............................] - ETA: 30:23 - loss: 0.0709 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 54/150\n",
      "  128/78101 [..............................] - ETA: 30:26 - loss: 0.0671 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 55/150\n",
      "  128/78101 [..............................] - ETA: 32:39 - loss: 0.0647 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 56/150\n",
      "  128/78101 [..............................] - ETA: 30:26 - loss: 0.0654 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 57/150\n",
      "  128/78101 [..............................] - ETA: 30:42 - loss: 0.0669 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 58/150\n",
      "  128/78101 [..............................] - ETA: 30:34 - loss: 0.0637 - accuracy: 0.9868 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 59/150\n",
      "  128/78101 [..............................] - ETA: 30:53 - loss: 0.0641 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 60/150\n",
      "  128/78101 [..............................] - ETA: 30:31 - loss: 0.0647 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 61/150\n",
      "  128/78101 [..............................] - ETA: 30:44 - loss: 0.0647 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 62/150\n",
      "  128/78101 [..............................] - ETA: 30:45 - loss: 0.0667 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 63/150\n",
      "  128/78101 [..............................] - ETA: 30:37 - loss: 0.0667 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 64/150\n",
      "  128/78101 [..............................] - ETA: 30:42 - loss: 0.0669 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 65/150\n",
      "  128/78101 [..............................] - ETA: 30:36 - loss: 0.0705 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 66/150\n",
      "  128/78101 [..............................] - ETA: 30:39 - loss: 0.0644 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 67/150\n",
      "  128/78101 [..............................] - ETA: 30:40 - loss: 0.0686 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 68/150\n",
      "  128/78101 [..............................] - ETA: 31:04 - loss: 0.0704 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 69/150\n",
      "  128/78101 [..............................] - ETA: 31:28 - loss: 0.0642 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 70/150\n",
      "  128/78101 [..............................] - ETA: 35:21 - loss: 0.0651 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 71/150\n",
      "  128/78101 [..............................] - ETA: 32:14 - loss: 0.0646 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 72/150\n",
      "  128/78101 [..............................] - ETA: 31:47 - loss: 0.0662 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 73/150\n",
      "  128/78101 [..............................] - ETA: 31:51 - loss: 0.0672 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 74/150\n",
      "  128/78101 [..............................] - ETA: 31:53 - loss: 0.0682 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 75/150\n",
      "  128/78101 [..............................] - ETA: 31:45 - loss: 0.0620 - accuracy: 0.9877 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 76/150\n",
      "  128/78101 [..............................] - ETA: 31:54 - loss: 0.0683 - accuracy: 0.9853 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 77/150\n",
      "  128/78101 [..............................] - ETA: 31:40 - loss: 0.0644 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 78/150\n",
      "  128/78101 [..............................] - ETA: 31:57 - loss: 0.0665 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 79/150\n",
      "  128/78101 [..............................] - ETA: 31:28 - loss: 0.0622 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 80/150\n",
      "  128/78101 [..............................] - ETA: 31:48 - loss: 0.0676 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 81/150\n",
      "  128/78101 [..............................] - ETA: 31:43 - loss: 0.0634 - accuracy: 0.9872 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 82/150\n",
      "  128/78101 [..............................] - ETA: 31:47 - loss: 0.0634 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 83/150\n",
      "  128/78101 [..............................] - ETA: 31:42 - loss: 0.0690 - accuracy: 0.9852 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 84/150\n",
      "  128/78101 [..............................] - ETA: 30:10 - loss: 0.0648 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00average min val_loss: 0.06618080392608106 -- epochs: [96, 84] -- time: 722.93 seconds\n",
      "{'lstm_layer_size': 256, 'lstm_dropout': 0.2, 'num_mid_dense': 0, 'output_dim': 100}\n",
      "Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/150\n",
      "  128/78101 [..............................] - ETA: 3:10:01 - loss: 0.6942 - accuracy: 0.4705 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/150\n",
      "  128/78101 [..............................] - ETA: 26:43 - loss: 0.6772 - accuracy: 0.7927 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/150\n",
      "  128/78101 [..............................] - ETA: 26:32 - loss: 0.6572 - accuracy: 0.9160 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/150\n",
      "  128/78101 [..............................] - ETA: 26:12 - loss: 0.6285 - accuracy: 0.9614 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/150\n",
      "  128/78101 [..............................] - ETA: 26:51 - loss: 0.5770 - accuracy: 0.9745 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/150\n",
      "  128/78101 [..............................] - ETA: 27:10 - loss: 0.4662 - accuracy: 0.9773 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/150\n",
      "  128/78101 [..............................] - ETA: 27:17 - loss: 0.3529 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/150\n",
      "  128/78101 [..............................] - ETA: 28:18 - loss: 0.2686 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/150\n",
      "  128/78101 [..............................] - ETA: 28:45 - loss: 0.1967 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/150\n",
      "  128/78101 [..............................] - ETA: 30:06 - loss: 0.1474 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/150\n",
      "  128/78101 [..............................] - ETA: 30:07 - loss: 0.1114 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/150\n",
      "  128/78101 [..............................] - ETA: 30:16 - loss: 0.0921 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/150\n",
      "  128/78101 [..............................] - ETA: 30:19 - loss: 0.0799 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/150\n",
      "  128/78101 [..............................] - ETA: 30:21 - loss: 0.0764 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/150\n",
      "  128/78101 [..............................] - ETA: 29:48 - loss: 0.0696 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/150\n",
      "  128/78101 [..............................] - ETA: 29:28 - loss: 0.0763 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/150\n",
      "  128/78101 [..............................] - ETA: 29:48 - loss: 0.0735 - accuracy: 0.9869 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/150\n",
      "  128/78101 [..............................] - ETA: 29:50 - loss: 0.0748 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/150\n",
      "  128/78101 [..............................] - ETA: 31:51 - loss: 0.0797 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/150\n",
      "  128/78101 [..............................] - ETA: 30:06 - loss: 0.0830 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/150\n",
      "  128/78101 [..............................] - ETA: 30:28 - loss: 0.0774 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/150\n",
      "  128/78101 [..............................] - ETA: 31:26 - loss: 0.0764 - accuracy: 0.9859 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/150\n",
      "  128/78101 [..............................] - ETA: 29:39 - loss: 0.0752 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/150\n",
      "  128/78101 [..............................] - ETA: 30:26 - loss: 0.0918 - accuracy: 0.9848 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-082b19f4235e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m }\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[0mall_hists\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid_search_es\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_b\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_create_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msearch_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m150\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mbest_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_hist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_hists\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\OneDrive\\Dokumente\\Studium\\TUM\\Kurse\\Informatik\\Semester 5\\ADNLP\\so_nlp\\toolbox\\training.py\u001b[0m in \u001b[0;36mgrid_search_es\u001b[1;34m(X, y, create_model, search_params, max_epochs)\u001b[0m\n\u001b[0;32m     82\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m             hist = model.fit(X_train, y_train, batch_size=128, validation_data=[X_test, y_test], epochs=max_epochs,\n\u001b[1;32m---> 84\u001b[1;33m                              callbacks=callbacks)\n\u001b[0m\u001b[0;32m     85\u001b[0m             \u001b[0mhists\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m             \u001b[0mval_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"val_loss\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msplit_states\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 224\u001b[1;33m           distribution_strategy=strategy)\n\u001b[0m\u001b[0;32m    225\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    546\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 547\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    548\u001b[0m     \u001b[0mval_adapter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36m_process_inputs\u001b[1;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, shuffle, steps, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m         \u001b[0mcheck_steps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 594\u001b[1;33m         steps=steps)\n\u001b[0m\u001b[0;32m    595\u001b[0m   adapter = adapter_cls(\n\u001b[0;32m    596\u001b[0m       \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[0;32m   2470\u001b[0m           \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2471\u001b[0m           \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2472\u001b[1;33m           exception_prefix='input')\n\u001b[0m\u001b[0;32m   2473\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2474\u001b[0m     \u001b[1;31m# Get typespecs for the input data and sanitize it if necessary.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    504\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    504\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    505\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 506\u001b[1;33m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    507\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m       \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\numeric.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m    536\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m     \"\"\"\n\u001b[1;32m--> 538\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from toolbox.training import grid_search_es\n",
    "\n",
    "search_params = {\n",
    "    # conduct big grid search with these params\n",
    "    \"lstm_layer_size\": [256,128],\n",
    "    \"lstm_dropout\": [0.0,0.2,0.4],\n",
    "    \"num_mid_dense\": [1, 0],\n",
    "    \n",
    "    # test grid search with these params (comment out for actual run)\n",
    "    #\"lstm_layer_size\": [16],\n",
    "    #\"lstm_dropout\": [0.0],\n",
    "    #\"num_mid_dense\": [1, 0],\n",
    "    # don#t change\n",
    "    \"output_dim\": [y.shape[-1]]\n",
    "}\n",
    "\n",
    "all_hists = grid_search_es([X_b, X_t], y, tb_create_model, search_params, max_epochs=150)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Parameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set our model-paramter to the results of the grid search. Feel free to run it on your own or set parameters manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best combindation: {'lstm_layer_size': 256, 'lstm_dropout': 0.0, 'num_mid_dense': 1, 'output_dim': 100}\n",
      "avg min val_loss: 0.06613914214908728 -- epoch counts: [100, 100]\n"
     ]
    }
   ],
   "source": [
    "# Chooses the parameter configuration, which lead to the lowest loss during the grid search\n",
    "best_params, best_hist, best_loss = min(all_hists, key=lambda x: x[2])\n",
    "\n",
    "epoch_lengths = [len(h[\"val_loss\"]) for h in best_hist]\n",
    "print(f\"best combindation: {best_params}\")\n",
    "print(f\"avg min val_loss: {best_loss} -- epoch counts: {epoch_lengths}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 100)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 100)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 100)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 100)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          365568      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          365568      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          65664       concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 100)          12900       dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 809,700\n",
      "Trainable params: 809,700\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tb_create_model(**best_params)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 78101 samples, validate on 19526 samples\n",
      "Epoch 1/300\n",
      "  128/78101 [..............................] - ETA: 9:32 - loss: 0.6818 - accuracy: 0.7149INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 37:27:01 - loss: 0.6818 - accuracy: 0.7149 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 2/300\n",
      "WARNING:tensorflow:Method (on_train_batch_end) is slow compared to the batch update (1.501223). Check your callbacks.\n",
      "  128/78101 [..............................] - ETA: 29:10 - loss: 0.6696 - accuracy: 0.7603INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 3:18:50 - loss: 0.6696 - accuracy: 0.7603 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 3/300\n",
      "  128/78101 [..............................] - ETA: 1:06 - loss: 0.6506 - accuracy: 0.8077INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:45:26 - loss: 0.6506 - accuracy: 0.8077 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 4/300\n",
      "  128/78101 [..............................] - ETA: 36s - loss: 0.6154 - accuracy: 0.8314INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 4:20:16 - loss: 0.6154 - accuracy: 0.8314 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 5/300\n",
      "  128/78101 [..............................] - ETA: 51s - loss: 0.5481 - accuracy: 0.8405INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 3:16:00 - loss: 0.5481 - accuracy: 0.8405 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 6/300\n",
      "  128/78101 [..............................] - ETA: 48s - loss: 0.4586 - accuracy: 0.8630INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:30:36 - loss: 0.4586 - accuracy: 0.8630 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 7/300\n",
      "  128/78101 [..............................] - ETA: 1:18 - loss: 0.3848 - accuracy: 0.8805INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 3:44:36 - loss: 0.3848 - accuracy: 0.8805 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 8/300\n",
      "  128/78101 [..............................] - ETA: 1:23 - loss: 0.3291 - accuracy: 0.8892INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:33:13 - loss: 0.3291 - accuracy: 0.8892 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 9/300\n",
      "  128/78101 [..............................] - ETA: 7:31 - loss: 0.2819 - accuracy: 0.8924INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 5:42:42 - loss: 0.2819 - accuracy: 0.8924 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 10/300\n",
      "  128/78101 [..............................] - ETA: 2:34 - loss: 0.2340 - accuracy: 0.9171INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:34:48 - loss: 0.2340 - accuracy: 0.9171 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 11/300\n",
      "  128/78101 [..............................] - ETA: 1:00 - loss: 0.1961 - accuracy: 0.9445INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 3:11:55 - loss: 0.1961 - accuracy: 0.9445 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 12/300\n",
      "  128/78101 [..............................] - ETA: 16:18 - loss: 0.1608 - accuracy: 0.9588INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:48:55 - loss: 0.1608 - accuracy: 0.9588 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 13/300\n",
      "  128/78101 [..............................] - ETA: 1:15 - loss: 0.1280 - accuracy: 0.9582INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 18:28:19 - loss: 0.1280 - accuracy: 0.9582 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 14/300\n",
      "  128/78101 [..............................] - ETA: 3:24 - loss: 0.1113 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:27:52 - loss: 0.1113 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 15/300\n",
      "  128/78101 [..............................] - ETA: 1:23 - loss: 0.1019 - accuracy: 0.9861INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:53:51 - loss: 0.1019 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 16/300\n",
      "  128/78101 [..............................] - ETA: 3:07 - loss: 0.0920 - accuracy: 0.9862INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 26:07:51 - loss: 0.0920 - accuracy: 0.9862 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 17/300\n",
      "  128/78101 [..............................] - ETA: 3:19 - loss: 0.0841 - accuracy: 0.9873INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:31:58 - loss: 0.0841 - accuracy: 0.9873 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 18/300\n",
      "  128/78101 [..............................] - ETA: 1:05 - loss: 0.0858 - accuracy: 0.9857INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:32:49 - loss: 0.0858 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 19/300\n",
      "  128/78101 [..............................] - ETA: 1:07 - loss: 0.0804 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 32:35:00 - loss: 0.0804 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 20/300\n",
      "  128/78101 [..............................] - ETA: 3:19 - loss: 0.0906 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:29:28 - loss: 0.0906 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 21/300\n",
      "  128/78101 [..............................] - ETA: 1:09 - loss: 0.0849 - accuracy: 0.9867INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:34:40 - loss: 0.0849 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 22/300\n",
      "  128/78101 [..............................] - ETA: 1:10 - loss: 0.0829 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 42:30:11 - loss: 0.0829 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 23/300\n",
      "  128/78101 [..............................] - ETA: 3:00 - loss: 0.0767 - accuracy: 0.9871INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:40:28 - loss: 0.0767 - accuracy: 0.9871 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 24/300\n",
      "  128/78101 [..............................] - ETA: 1:25 - loss: 0.0816 - accuracy: 0.9866INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:17:29 - loss: 0.0816 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 25/300\n",
      "  128/78101 [..............................] - ETA: 1:02 - loss: 0.0835 - accuracy: 0.9870INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 35:43:44 - loss: 0.0835 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 26/300\n",
      "  128/78101 [..............................] - ETA: 3:27 - loss: 0.0842 - accuracy: 0.9856INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:16:04 - loss: 0.0842 - accuracy: 0.9856 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 27/300\n",
      "  128/78101 [..............................] - ETA: 1:00 - loss: 0.0766 - accuracy: 0.9857INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:10:49 - loss: 0.0766 - accuracy: 0.9857 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 28/300\n",
      "  128/78101 [..............................] - ETA: 1:32 - loss: 0.0769 - accuracy: 0.9860INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:11:04 - loss: 0.0769 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 29/300\n",
      "  128/78101 [..............................] - ETA: 1:45 - loss: 0.0718 - accuracy: 0.9870INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 63:54:41 - loss: 0.0718 - accuracy: 0.9870 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 30/300\n",
      "  128/78101 [..............................] - ETA: 5:24 - loss: 0.0747 - accuracy: 0.9865INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 3:02:56 - loss: 0.0747 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 31/300\n",
      "  128/78101 [..............................] - ETA: 2:39 - loss: 0.0739 - accuracy: 0.9866INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:11:45 - loss: 0.0739 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 32/300\n",
      "  128/78101 [..............................] - ETA: 1:35 - loss: 0.0741 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:32:31 - loss: 0.0741 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 33/300\n",
      "  128/78101 [..............................] - ETA: 1:07 - loss: 0.0748 - accuracy: 0.9864INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 81:26:02 - loss: 0.0748 - accuracy: 0.9864 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 34/300\n",
      "  128/78101 [..............................] - ETA: 3:21 - loss: 0.0712 - accuracy: 0.9863INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:20:56 - loss: 0.0712 - accuracy: 0.9863 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 35/300\n",
      "  128/78101 [..............................] - ETA: 1:15 - loss: 0.0752 - accuracy: 0.9855INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:27:53 - loss: 0.0752 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 36/300\n",
      "  128/78101 [..............................] - ETA: 1:22 - loss: 0.0730 - accuracy: 0.9861INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:36:12 - loss: 0.0730 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 37/300\n",
      "  128/78101 [..............................] - ETA: 1:06 - loss: 0.0695 - accuracy: 0.9861INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:27:07 - loss: 0.0695 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 38/300\n",
      "  128/78101 [..............................] - ETA: 1:33 - loss: 0.0729 - accuracy: 0.9855INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 69:35:42 - loss: 0.0729 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 39/300\n",
      "  128/78101 [..............................] - ETA: 3:19 - loss: 0.0709 - accuracy: 0.9858INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:28:23 - loss: 0.0709 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 40/300\n",
      "  128/78101 [..............................] - ETA: 1:15 - loss: 0.0708 - accuracy: 0.9866INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:18:13 - loss: 0.0708 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 41/300\n",
      "  128/78101 [..............................] - ETA: 1:31 - loss: 0.0695 - accuracy: 0.9858INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:23:22 - loss: 0.0695 - accuracy: 0.9858 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 42/300\n",
      "  128/78101 [..............................] - ETA: 1:00 - loss: 0.0683 - accuracy: 0.9860INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:23:34 - loss: 0.0683 - accuracy: 0.9860 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 43/300\n",
      "  128/78101 [..............................] - ETA: 1:16 - loss: 0.0696 - accuracy: 0.9861INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 110:18:01 - loss: 0.0696 - accuracy: 0.9861 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 44/300\n",
      "  128/78101 [..............................] - ETA: 3:08 - loss: 0.0663 - accuracy: 0.9866INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:29:20 - loss: 0.0663 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 45/300\n",
      "  128/78101 [..............................] - ETA: 1:21 - loss: 0.0739 - accuracy: 0.9855INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:46:12 - loss: 0.0739 - accuracy: 0.9855 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 46/300\n",
      "  128/78101 [..............................] - ETA: 1:03 - loss: 0.0659 - accuracy: 0.9867INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:27:45 - loss: 0.0659 - accuracy: 0.9867 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 47/300\n",
      "  128/78101 [..............................] - ETA: 1:05 - loss: 0.0697 - accuracy: 0.9866INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:27:24 - loss: 0.0697 - accuracy: 0.9866 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 48/300\n",
      "  128/78101 [..............................] - ETA: 1:07 - loss: 0.0672 - accuracy: 0.9865INFO:tensorflow:Assets written to: checkpoints\\20200204-121233\\assets\n",
      "  128/78101 [..............................] - ETA: 2:56:07 - loss: 0.0672 - accuracy: 0.9865 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00Epoch 49/300\n",
      "  128/78101 [..............................] - ETA: 2:01 - loss: 0.0687 - accuracy: 0.9859"
     ]
    }
   ],
   "source": [
    "# If you are working on linux or windows, pay attention to the file paths \"/\" and \"\\\\\" respectively\n",
    "\n",
    "import datetime\n",
    "\n",
    "model_name = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "log_dir=\"logs\\\\fit\\\\\" + model_name\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_loss\", patience=10, verbose=0),\n",
    "    TensorBoard(log_dir=log_dir, histogram_freq=1),\n",
    "    ModelCheckpoint(filepath=f\"checkpoints\\\\{model_name}\", monitor=\"val_loss\", restore_best_weights=True, verbose=0)\n",
    "]\n",
    "\n",
    "# Train and test split with two datasets. Requires the zip to make the split for the question body and the question title\n",
    "X_train_z, X_test_z, y_train, y_test = train_test_split(list(zip(X_b, X_t)), y, test_size=0.2)\n",
    "X_train = list(zip(*X_train_z))\n",
    "X_test = list(zip(*X_test_z))\n",
    "model.fit(x=X_train, y=y_train, batch_size=128, epochs = 300, validation_data=[X_test, y_test], callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = model.predict([X_test_t_padded, X_test_b_padded])\n",
    "\n",
    "l_pred = label_encoder.inverse_transform(binarize_model_output(predictions, threshold=0.10))\n",
    "l_true = label_encoder.inverse_transform(y_test)\n",
    "texts = test_data[tokenized_field]\n",
    "raw_texts = test_data[content_field]\n",
    "titles = test_data[\"Title\"]\n",
    "\n",
    "for pred, act, txt, raw_txt, title in zip(l_pred, l_true, texts, raw_texts, titles):\n",
    "    print(f\"TRUE: {act}\\nPREDICTION: {pred}\\n\")\n",
    "    print(f\"{title}\\n----------\")\n",
    "    print(raw_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation\n",
      "\n",
      "normalize_embeddings = True, learning_rate = 1, vocab_size = None, epochs=30\n",
      "Parameter Settings:\n",
      " Sample size = -1, Max. number of words per question = 100, Number of Top Labels used = 100\n",
      "\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, None, 100)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            [(None, None, 100)]  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "masking (Masking)               (None, None, 100)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "masking_1 (Masking)             (None, None, 100)    0           input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 256)          365568      masking[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 256)          365568      masking_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 512)          0           lstm[0][0]                       \n",
      "                                                                 lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          51300       concatenate[0][0]                \n",
      "==================================================================================================\n",
      "Total params: 782,436\n",
      "Trainable params: 782,436\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dschr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "C:\\Users\\dschr\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Metrics with optimized threshold of 0.43\n",
      " Macro Evaluation: f1_Score= 0.5090096015650044 , Recall = 0.44893302869566176 , Precision = 0.6111371903996836\n",
      " Micro Evaluation: f1_Score= 0.5972185778011021 , Recall = 0.5130362912314975 , Precision = 0.7144501412577169\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict([X_test_t_padded, X_test_b_padded], batch_size=64)\n",
    "output_evaluation(model, sample_size, max_question_words, n_top_labels, y_test, predictions, normalize_embeddings, 1, None, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19526, 100)\n",
      "(19526, 100)\n"
     ]
    }
   ],
   "source": [
    "print(predictions.shape)\n",
    "print(y_test.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
